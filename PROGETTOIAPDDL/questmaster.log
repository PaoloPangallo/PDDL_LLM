

Driver aborting after translate
INFO     Planner time: 0.09s

2025-06-29 14:46:45,390 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 634, in parse_task\n    task_name, task_domain_name, task_requirements, objects, init, goal, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 782, in parse_task_pddl\n    yield parse_init(context, init)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 617, in parse_init\n    atom = pddl.Atom(fact[0], fact[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 14:46:45,441 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 14:46:45,442 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "has-item",
    "open"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 14:46:45,446 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 14:46:45,452 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 14:48:35,075 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 14:48:35,081 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 14:48:35,082 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 14:48:35,093 [ERROR] ❌ Fallita la raffinazione automatica: ❌ DOMAIN block not found.
2025-06-29 14:48:35,127 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 14:48:35,132 [INFO] 127.0.0.1 - - [29/Jun/2025 14:48:35] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 14:48:35,150 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-144432-9cc722'} form_keys=[]
2025-06-29 14:48:35,254 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 14:48:35,327 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 14:48:35,328 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "has-item",
    "open"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 14:48:35,339 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 14:48:35,342 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 14:49:42,161 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 14:49:42,210 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-144432-9cc722
2025-06-29 14:49:42,215 [INFO] ✅ Riflessione completata.
2025-06-29 14:49:42,240 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 14:49:42,241 [INFO] 127.0.0.1 - - [29/Jun/2025 14:49:42] "GET /result?session=the_hero_must_reach_the_tower_-20250629-144432-9cc722 HTTP/1.1" 200 -
2025-06-29 14:49:42,296 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 14:49:42,300 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 14:49:42,314 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 14:49:42,314 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 14:49:42,315 [INFO] 127.0.0.1 - - [29/Jun/2025 14:49:42] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 14:49:42,316 [INFO] 127.0.0.1 - - [29/Jun/2025 14:49:42] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 14:54:22,953 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 14:54:22,956 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 14:54:22,957 [INFO] 127.0.0.1 - - [29/Jun/2025 14:54:22] "GET / HTTP/1.1" 200 -
2025-06-29 14:54:22,972 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 14:54:22,973 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 14:54:22,988 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 14:54:22,989 [INFO] 127.0.0.1 - - [29/Jun/2025 14:54:22] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 14:54:22,990 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 14:54:22,990 [INFO] 127.0.0.1 - - [29/Jun/2025 14:54:22] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 14:54:25,399 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 14:54:25,783 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 14:54:25,786 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 14:56:40,132 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 14:56:40,159 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 14:56:40,159 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 14:56:40,160 [WARNING] ⚠️ Generazione fallita: PDDL non valido.
2025-06-29 14:56:40,197 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 14:56:40,198 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 14:56:40,240 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-145425-38a75b'} form_keys=[]
2025-06-29 14:56:40,294 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 14:56:40,294 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "GET /result?session=the_hero_must_reach_the_tower_-20250629-145425-38a75b HTTP/1.1" 200 -
2025-06-29 14:56:40,365 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 14:56:40,367 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 14:56:40,372 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 14:56:40,372 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 14:56:40,375 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 14:56:40,376 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:23:10,475 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 15:23:10,769 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 15:23:10,780 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 15:27:08,080 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:27:08,951 [INFO] ⏱️ Planner terminato in 0.76s (exit code: 30)
2025-06-29 15:27:08,952 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/problem.pddl con lazy_greedy([ff()]) (dominio: simple_maze)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/problem.pddl --sas-file output.sas
Parsing...
translate exit code: 30

Driver aborting after translate
INFO     Planner time: 0.15s

2025-06-29 15:27:08,953 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 630, in parse_task\n    domain_name, domain_requirements, types, type_dict, constants, predicates, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 733, in parse_domain_pddl\n    the_axioms, the_actions = parse_axioms_and_actions(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 569, in parse_axioms_and_actions\n    action = parse_action(context, entry, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 523, in parse_action\n    cost = parse_effects(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 332, in parse_effects\n    tmp_effect = parse_effect(context, alist, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 393, in parse_effect\n    effects.append(parse_effect(context, eff, type_dict, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 434, in parse_effect\n    return pddl.SimpleEffect(parse_literal(context, alist, {}, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 305, in parse_literal\n    return pddl.Atom(pred_id, alist[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 15:27:09,000 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 15:27:09,001 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 15:27:09,018 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 15:27:09,031 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 15:29:17,258 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:29:17,318 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/llm_suggestion.pddl
2025-06-29 15:29:17,340 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 15:29:17,349 [INFO] 127.0.0.1 - - [29/Jun/2025 15:29:17] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 15:29:17,381 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-152310-eaf7bf'} form_keys=[]
2025-06-29 15:29:17,441 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 15:29:17,479 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 15:29:17,480 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 15:29:17,493 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 15:29:17,496 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 15:31:22,508 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:31:22,517 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 15:31:22,518 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 15:31:22,536 [WARNING] ⚠️ Errore durante la riflessione automatica: ❌ DOMAIN block not found.
2025-06-29 15:31:22,556 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 15:31:22,557 [INFO] 127.0.0.1 - - [29/Jun/2025 15:31:22] "GET /result?session=the_hero_must_reach_the_tower_-20250629-152310-eaf7bf HTTP/1.1" 200 -
2025-06-29 15:31:22,623 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:31:22,628 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:31:22,644 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:31:22,646 [INFO] 127.0.0.1 - - [29/Jun/2025 15:31:22] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:31:22,647 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:31:22,648 [INFO] 127.0.0.1 - - [29/Jun/2025 15:31:22] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:51:37,480 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 15:51:38,028 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 15:51:38,035 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 15:53:47,740 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:53:47,771 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 15:53:47,772 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 15:53:47,773 [WARNING] ⚠️ Generazione fallita: PDDL non valido.
2025-06-29 15:53:47,824 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 15:53:47,830 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:47] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 15:53:47,848 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-155137-a65466'} form_keys=[]
2025-06-29 15:53:47,921 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 15:53:47,922 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:47] "GET /result?session=the_hero_must_reach_the_tower_-20250629-155137-a65466 HTTP/1.1" 200 -
2025-06-29 15:53:47,992 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:53:47,997 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:53:48,009 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:53:48,011 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:53:48,013 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:53:48,014 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:48] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:55:14,311 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 15:55:14,317 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 15:55:14,318 [INFO] 127.0.0.1 - - [29/Jun/2025 15:55:14] "GET / HTTP/1.1" 200 -
2025-06-29 15:55:14,344 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:55:14,345 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:55:14,349 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:55:14,351 [INFO] 127.0.0.1 - - [29/Jun/2025 15:55:14] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:55:14,353 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:55:14,354 [INFO] 127.0.0.1 - - [29/Jun/2025 15:55:14] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:55:16,736 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 15:55:16,812 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 15:55:16,815 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 15:56:14,920 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:56:14,938 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 15:56:14,939 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 15:56:14,940 [WARNING] ⚠️ Generazione fallita: PDDL non valido.
2025-06-29 15:56:14,962 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 15:56:14,963 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:14] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 15:56:14,977 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-155516-32908e'} form_keys=[]
2025-06-29 15:56:15,015 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 15:56:15,016 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:15] "GET /result?session=the_hero_must_reach_the_tower_-20250629-155516-32908e HTTP/1.1" 200 -
2025-06-29 15:56:15,083 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:56:15,086 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:56:15,091 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:56:15,092 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:15] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:56:15,094 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:56:15,095 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:15] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 16:04:42,490 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 16:04:42,495 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 16:04:42,496 [INFO] 127.0.0.1 - - [29/Jun/2025 16:04:42] "GET / HTTP/1.1" 200 -
2025-06-29 16:04:42,518 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 16:04:42,519 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 16:04:42,526 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 16:04:42,527 [INFO] 127.0.0.1 - - [29/Jun/2025 16:04:42] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 16:04:42,529 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 16:04:42,530 [INFO] 127.0.0.1 - - [29/Jun/2025 16:04:42] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 16:04:44,806 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 16:04:44,896 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 16:04:44,900 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 16:07:47,003 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:07:47,531 [INFO] ⏱️ Planner terminato in 0.47s (exit code: 31)
2025-06-29 16:07:47,532 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/problem.pddl con lazy_greedy([ff()]) (dominio: robot-assembly)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/problem.pddl --sas-file output.sas
Parsing...
Error: Could not parse domain file: /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/domain.pddl
Reason: Tokens remaining after parsing: ( define ( function get-robots-at ?assembly-line ) ( all ( ?robot ) ( implies ( and ( eq ?robot ( type-of ?robot ) ) ( at-robot ?robot ?assembly-line ) ) true ) ) )
translate exit code: 31

Driver aborting after translate
INFO     Planner time: 0.09s

2025-06-29 16:07:47,533 [DEBUG] STDERR:

2025-06-29 16:07:47,563 [INFO] 🔁 LLM invoked with error: 
2025-06-29 16:07:47,565 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "assembled"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 16:07:47,573 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 16:07:47,575 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 16:09:32,355 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:09:32,410 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/llm_suggestion.pddl
2025-06-29 16:09:32,424 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 16:09:32,427 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 16:09:32,457 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-160444-e2500e'} form_keys=[]
2025-06-29 16:09:32,516 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 16:09:32,517 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "GET /result?session=the_hero_must_reach_the_tower_-20250629-160444-e2500e HTTP/1.1" 200 -
2025-06-29 16:09:32,603 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 16:09:32,604 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 16:09:32,612 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 16:09:32,613 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 16:09:32,614 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 16:09:32,614 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 16:24:33,937 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 16:24:34,512 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 16:24:34,522 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 16:27:49,130 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:27:49,901 [INFO] ⏱️ Planner terminato in 0.67s (exit code: 30)
2025-06-29 16:27:49,902 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/problem.pddl con lazy_greedy([ff()]) (dominio: my_domain)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/problem.pddl --sas-file output.sas
Parsing...
translate exit code: 30

Driver aborting after translate
INFO     Planner time: 0.23s

2025-06-29 16:27:49,903 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 630, in parse_task\n    domain_name, domain_requirements, types, type_dict, constants, predicates, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 733, in parse_domain_pddl\n    the_axioms, the_actions = parse_axioms_and_actions(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 569, in parse_axioms_and_actions\n    action = parse_action(context, entry, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 523, in parse_action\n    cost = parse_effects(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 332, in parse_effects\n    tmp_effect = parse_effect(context, alist, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 393, in parse_effect\n    effects.append(parse_effect(context, eff, type_dict, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 434, in parse_effect\n    return pddl.SimpleEffect(parse_literal(context, alist, {}, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 305, in parse_literal\n    return pddl.Atom(pred_id, alist[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 16:27:49,952 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 16:27:49,953 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "on",
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 16:27:49,967 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 16:27:49,975 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 16:29:23,118 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:29:23,166 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/llm_suggestion.pddl
2025-06-29 16:29:23,189 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 16:29:23,194 [INFO] 127.0.0.1 - - [29/Jun/2025 16:29:23] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 16:29:23,224 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-162433-9870fb'} form_keys=[]
2025-06-29 16:29:23,269 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 16:29:23,299 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 16:29:23,299 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "on",
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 16:29:23,306 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 16:29:23,308 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 16:30:31,686 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:30:31,718 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb
2025-06-29 16:30:31,723 [INFO] ✅ Riflessione completata.
2025-06-29 16:30:31,743 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 16:30:31,745 [INFO] 127.0.0.1 - - [29/Jun/2025 16:30:31] "GET /result?session=the_hero_must_reach_the_tower_-20250629-162433-9870fb HTTP/1.1" 200 -
2025-06-29 16:30:31,818 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 16:30:31,823 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 16:30:31,836 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 16:30:31,837 [INFO] 127.0.0.1 - - [29/Jun/2025 16:30:31] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 16:30:31,838 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 16:30:31,838 [INFO] 127.0.0.1 - - [29/Jun/2025 16:30:31] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:14:20,468 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-06-29 17:14:20,469 [INFO] [33mPress CTRL+C to quit[0m
2025-06-29 17:14:29,673 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:14:29,728 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:14:29,731 [INFO] 127.0.0.1 - - [29/Jun/2025 17:14:29] "GET / HTTP/1.1" 200 -
2025-06-29 17:14:29,769 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:14:29,770 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:14:29,790 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:14:29,791 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:14:29,792 [INFO] 127.0.0.1 - - [29/Jun/2025 17:14:29] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:14:29,792 [INFO] 127.0.0.1 - - [29/Jun/2025 17:14:29] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:14:32,893 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 17:14:33,359 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 17:14:33,364 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 17:19:26,322 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 17:19:27,843 [INFO] ⏱️ Planner terminato in 1.36s (exit code: 30)
2025-06-29 17:19:27,845 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/problem.pddl con lazy_greedy([ff()]) (dominio: robot-world)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/problem.pddl --sas-file output.sas
Parsing...
translate exit code: 30

Driver aborting after translate
INFO     Planner time: 0.36s

2025-06-29 17:19:27,860 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 634, in parse_task\n    task_name, task_domain_name, task_requirements, objects, init, goal, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 782, in parse_task_pddl\n    yield parse_init(context, init)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 617, in parse_init\n    atom = pddl.Atom(fact[0], fact[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 17:19:28,113 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 17:19:28,116 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 17:19:28,144 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 17:19:28,160 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 17:20:45,651 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 17:20:45,696 [ERROR] ❌ Fallita la raffinazione automatica: ❌ DOMAIN non valido. Controlla 'llm_raw_output.txt'
2025-06-29 17:20:45,724 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 17:20:45,740 [INFO] 127.0.0.1 - - [29/Jun/2025 17:20:45] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 17:20:45,805 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-171432-dc3f57'} form_keys=[]
2025-06-29 17:20:45,872 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 17:20:45,962 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 17:20:45,963 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 17:20:45,976 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 17:20:45,981 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 17:23:47,560 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 17:23:47,565 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 17:23:47,610 [WARNING] ⚠️ Output LLM incompleto o malformato:
I am an assistant that can help you with PDDL files correction based on the error messages provided. However, please note that I can only provide guidance for common issues, and you may need to adjust the corrections based on your specific context. Here's a sample correction for a simple example:

Let's say the original domain file contains:

=== DOMAIN START ===
(define (domain my_domain)
   (:requirements :equality :quantifiers :action-cost)
   (:predicates
      (at ?x - Location)
      (has_
2025-06-29 17:23:47,638 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57
2025-06-29 17:23:47,649 [INFO] ✅ Riflessione completata.
2025-06-29 17:23:47,940 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 17:23:47,942 [INFO] 127.0.0.1 - - [29/Jun/2025 17:23:47] "GET /result?session=the_hero_must_reach_the_tower_-20250629-171432-dc3f57 HTTP/1.1" 200 -
2025-06-29 17:23:48,099 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:23:48,109 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:23:48,135 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:23:48,136 [INFO] 127.0.0.1 - - [29/Jun/2025 17:23:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:23:48,138 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:23:48,139 [INFO] 127.0.0.1 - - [29/Jun/2025 17:23:48] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:35:36,522 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:35:36,530 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:35:36,533 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:36] "GET / HTTP/1.1" 200 -
2025-06-29 17:35:36,586 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:35:36,589 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:35:36,626 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:35:36,628 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:36] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:35:36,630 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:35:36,631 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:36] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:35:38,102 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:35:38,105 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:35:38,107 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:38] "GET / HTTP/1.1" 200 -
2025-06-29 17:35:38,151 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:35:38,153 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:35:38,213 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:35:38,220 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:38] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:35:38,245 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:35:38,254 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:38] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:39:29,508 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:39:29,512 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:39:29,516 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:29] "GET / HTTP/1.1" 200 -
2025-06-29 17:39:29,564 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:39:29,567 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:39:29,584 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:39:29,586 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:29] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:39:29,591 [DEBUG] ← RESPONSE GET /static/js/index.js status=200
2025-06-29 17:39:29,600 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:29] "GET /static/js/index.js HTTP/1.1" 200 -
2025-06-29 17:39:31,038 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:39:31,041 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:39:31,042 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:31] "GET / HTTP/1.1" 200 -
2025-06-29 17:39:31,088 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:39:31,090 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:39:31,106 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:39:31,107 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:31] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:39:31,113 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:39:31,114 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:31] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:39:32,187 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:39:32,189 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:39:32,190 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:32] "GET / HTTP/1.1" 200 -
2025-06-29 17:39:32,236 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:39:32,239 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:39:32,257 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:39:32,258 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:39:32,263 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:39:32,265 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:32] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
[2025-07-04 11:33:37,199] INFO: 📤 Invio prompt a Ollama con modello: mistral
2025-07-04 18:27:32,761 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:27:32,766 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 149, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1087, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 65, in get_source
    return self._get_source_fast(environment, template)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 99, in _get_source_fast
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: index.html
2025-07-04 18:27:32,813 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:27:32,814 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:31:04,825 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:31:04,871 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 1, in top-level template code
    {% extends "base.html" %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/base.html", line 15, in top-level template code
    {% block content %}{% endblock %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 24, in block 'content'
    {{ csrf_token() }}
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/utils.py", line 92, in from_obj
    if hasattr(obj, "jinja_pass_arg"):
jinja2.exceptions.UndefinedError: 'csrf_token' is undefined
2025-07-04 18:31:04,955 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:31:04,955 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:34:51,374 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:34:51,429 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 1, in top-level template code
    {% extends "base.html" %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/base.html", line 15, in top-level template code
    {% block content %}{% endblock %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 24, in block 'content'
    {{ csrf_token() }}
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/utils.py", line 92, in from_obj
    if hasattr(obj, "jinja_pass_arg"):
jinja2.exceptions.UndefinedError: 'csrf_token' is undefined
2025-07-04 18:34:51,512 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:34:51,513 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:37:53,485 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:37:53,540 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 1, in top-level template code
    {% extends "base.html" %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/base.html", line 15, in top-level template code
    {% block content %}{% endblock %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 24, in block 'content'
    {{ csrf_token() }}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/app_factory.py", line 57, in <lambda>
    self.app.context_processor(lambda: {"csrf_token": lambda: csrf.generate_csrf()})
AttributeError: 'CSRFProtect' object has no attribute 'generate_csrf'
2025-07-04 18:37:53,640 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:37:53,641 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:39:58,454 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:39:58,490 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:39:58,540 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:39:58,554 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:39:58,556 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:39:58,558 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:39:58,560 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:39:58,562 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:39:58,563 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:39:58,594 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:39:58,596 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:39:58,596 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:39:58,598 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 18:39:58,598 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 18:39:58,772 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:39:58,789 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 18:44:05,020 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:44:05,055 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:44:05,107 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:44:05,111 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:44:05,115 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:44:05,117 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:44:05,119 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:44:05,121 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:44:05,129 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:44:05,130 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:44:05,134 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:44:05,135 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 18:44:05,140 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:44:05,147 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 18:44:05,152 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:44:05,180 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 18:44:10,371 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:44:10,383 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:44:10,399 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:44:10,400 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:44:10,568 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:10,570 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:10,574 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:10,574 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:12,621 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:44:12,622 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:44:12,668 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:44:12,669 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:44:12,672 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:44:12,674 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:44:12,676 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:44:12,680 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:44:12,682 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:44:12,684 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:44:12,688 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:44:12,690 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 18:44:12,693 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 18:44:12,694 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:44:12,698 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:44:12,715 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 18:44:12,818 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:44:12,834 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:12,836 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:12,839 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:12,840 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:12,854 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 18:44:31,953 [DEBUG] → REQUEST POST /api/chatbot/message args={} form=[]
2025-07-04 18:44:31,954 [DEBUG] ← RESPONSE POST /api/chatbot/message status=404
2025-07-04 18:45:44,077 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 18:45:44,091 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 18:45:44,340 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-04 18:45:44,342 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-04 18:47:08,033 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:47:08,035 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:47:08,085 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:47:08,087 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:47:08,089 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:47:08,091 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:47:08,093 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:47:08,094 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:47:08,096 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:47:08,099 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:47:08,102 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 18:47:08,103 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 18:47:08,105 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:47:08,107 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:47:08,119 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:47:08,127 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 18:47:08,241 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:47:08,263 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:08,272 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:08,273 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:08,281 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:08,289 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 18:47:11,781 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:47:11,805 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:47:11,817 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:47:11,818 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:47:11,867 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:11,869 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:11,881 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:11,881 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:13,118 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:47:13,120 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:47:13,158 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:47:13,161 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:47:13,163 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:47:13,166 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:47:13,168 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:47:13,170 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:47:13,171 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:47:13,173 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:47:13,176 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 18:47:13,176 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 18:47:13,179 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:47:13,182 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:47:13,196 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:47:13,198 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 18:47:13,220 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:47:13,245 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:13,247 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:13,253 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:13,254 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:13,282 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 18:48:45,660 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 18:48:45,667 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 18:55:38,656 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:55:38,687 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:55:38,741 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:55:38,743 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:55:38,745 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:55:38,747 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:55:38,748 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:55:38,773 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:55:38,777 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 18:55:38,778 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:55:38,778 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 18:55:38,785 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 18:55:38,801 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:55:38,825 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:01:47,990 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:01:48,025 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:01:48,096 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:01:48,097 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:01:48,100 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:01:48,102 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:01:48,104 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:01:48,132 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:01:48,135 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:01:48,136 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:01:48,136 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:01:48,140 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:01:48,176 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:01:48,207 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:04:50,318 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:04:50,353 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:04:50,391 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:04:50,392 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:04:50,395 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:04:50,396 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:04:50,397 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:04:50,415 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:04:50,418 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:04:50,419 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:04:50,419 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 19:04:50,431 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:04:50,435 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:04:50,461 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:04:54,980 [DEBUG] → REQUEST GET / args={'lore_path': ''} form=[]
2025-07-04 19:04:54,983 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:04:55,038 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:04:55,041 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:04:55,046 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:04:55,049 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:04:55,050 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:04:55,055 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:04:55,058 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:04:55,059 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 19:04:55,063 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:04:55,077 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:05:40,102 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:05:40,113 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:05:40,127 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:05:40,128 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:05:40,195 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:40,196 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:40,203 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:40,204 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:41,402 [DEBUG] → REQUEST GET / args={'lore_path': ''} form=[]
2025-07-04 19:05:41,406 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:05:41,431 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:05:41,432 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:05:41,441 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:05:41,443 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:05:41,445 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:05:41,447 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:05:41,448 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:05:41,456 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 19:05:41,456 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 19:05:41,457 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:05:41,459 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:05:41,476 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 19:05:41,604 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:05:41,617 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:41,621 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:41,634 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:41,635 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:41,661 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 19:08:30,060 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:08:30,111 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:08:30,184 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:08:30,187 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:08:30,191 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:08:30,193 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:08:30,224 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:08:30,225 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 19:08:30,226 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:08:30,247 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:08:30,438 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:08:30,494 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:08:30,627 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:08:30,646 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:08:31,368 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:08:31,381 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:08:31,383 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:08:31,384 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:08:31,513 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:31,514 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:31,521 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:31,522 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:33,129 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:08:33,132 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:08:33,174 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:08:33,175 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:08:33,187 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:08:33,189 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:08:33,191 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:08:33,192 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:08:33,197 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 19:08:33,199 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:08:33,200 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 19:08:33,223 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 19:08:33,340 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:08:33,351 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:08:33,355 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:33,357 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:33,362 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:33,365 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:33,367 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:08:33,386 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 19:14:23,132 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:14:23,165 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:14:23,217 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:14:23,222 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:14:23,224 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:14:23,226 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:14:23,243 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:14:23,244 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:14:23,244 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:14:23,256 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:14:23,294 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:14:23,323 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:14:23,469 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:14:23,485 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:14:23,584 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 19:14:23,591 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 19:14:25,397 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:14:25,407 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:14:25,414 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:14:25,415 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:14:25,536 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:25,541 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:25,546 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:25,548 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:27,189 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:14:27,191 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:14:27,262 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:14:27,265 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:14:27,267 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:14:27,269 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:14:27,272 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:14:27,275 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:14:27,291 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 19:14:27,294 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 19:14:27,295 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:14:27,330 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 19:14:27,379 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:14:27,395 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:27,397 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:14:27,399 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:27,404 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:27,406 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:27,407 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 19:14:27,414 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:14:27,426 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 19:14:27,427 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 19:14:31,307 [DEBUG] → REQUEST POST /api/pipeline/run args={} form=[]
[2025-07-04 19:14:31,692] INFO: 📤 Invio prompt a Ollama con modello: mistral
2025-07-04 19:18:00,148 [DEBUG] ← RESPONSE POST /api/pipeline/run status=200
2025-07-04 19:18:00,219 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-04 19:18:00,222 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]

[2025-07-07 14:15:51,601] INFO: 📤 Invio prompt a Ollama con modello: mistral
[2025-07-07 14:28:58,624] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 15:06:41,927] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 15:47:11,900] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 15:55:59,004] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 16:03:52,732] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 16:22:38,463] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 16:34:54,772] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 17:01:49,877] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 17:09:12,315] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 09:52:36,616] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 10:48:26,015 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 10:48:26,016 [DEBUG] ← RESPONSE GET / status=404
2025-07-08 10:48:26,192 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-08 10:48:26,193 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-08 10:51:43,682 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 10:51:43,683 [DEBUG] ← RESPONSE GET / status=404
2025-07-08 10:52:40,250 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 10:52:40,279 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 10:52:40,317 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 10:52:40,319 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 10:52:40,336 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 10:52:40,337 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
[2025-07-08 11:01:45,653] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 11:05:49,617] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 11:08:29,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 11:15:21,089] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 11:18:47,405 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 11:18:47,436 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 11:18:47,480 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 11:18:47,485 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 11:18:47,507 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 11:18:47,509 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 11:19:42,915 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 11:19:42,983 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 11:19:43,084 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 11:19:43,089 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 11:19:43,142 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 11:19:43,144 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 11:19:52,740 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 11:19:53,752 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 16:25:54,122 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:25:54,139 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:25:54,565 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:25:54,741 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:25:56,195 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-08 16:25:56,198 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-08 16:40:43,025 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:40:43,044 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:40:43,061 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:40:43,062 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:40:43,073 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:40:43,074 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:42:02,699 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:02,703 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:02,718 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:02,719 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:02,721 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:02,723 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:42:04,620 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:04,625 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:04,643 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:04,644 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:04,649 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:04,651 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:42:25,221 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:25,244 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:25,258 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:25,259 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:25,271 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:25,272 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:42:34,664 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:34,675 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:42:34,676 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:42:34,677 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:37,545 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:37,557 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:37,573 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:42:37,574 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:37,574 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:42:37,575 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:37,581 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:42:37,587 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:44:48,119 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:44:48,142 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:44:48,162 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:44:48,164 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:44:48,175 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:44:48,175 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:44:51,318 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:44:51,332 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:44:51,333 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:44:51,347 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:44:52,650 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:44:52,653 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:44:52,675 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:44:52,676 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:44:52,677 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:44:52,678 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:44:52,684 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:44:52,686 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:46:59,140 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:46:59,162 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:46:59,180 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:46:59,181 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:46:59,191 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:46:59,191 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:47:02,427 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:47:02,444 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:47:02,445 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:47:02,450 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:47:03,877 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:47:03,886 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:47:03,904 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:47:03,905 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:47:03,906 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:47:03,911 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:47:03,917 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:47:03,919 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:48:19,573 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:48:19,595 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:48:19,612 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:48:19,613 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:48:19,623 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:48:19,623 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:48:21,788 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:48:21,809 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:48:21,810 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:48:21,813 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:48:23,420 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:48:23,423 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:48:23,451 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:48:23,452 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:48:23,453 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:48:23,454 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:48:23,457 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:48:23,457 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:48:26,576 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 16:48:26,723 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:08:08,883 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:08:08,907 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:08:08,923 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:08:08,925 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:08:08,936 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:08:08,936 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 17:08:15,850 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:08:16,051 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:18:22,482 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:18:22,504 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:18:22,521 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:18:22,522 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:18:22,523 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:18:22,528 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:18:26,501 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:18:26,502 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:18:32,452 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:18:32,458 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:18:32,460 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:18:32,461 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:18:38,565 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:18:38,569 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:18:38,590 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:18:38,590 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:18:38,593 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:18:38,594 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:18:38,595 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:18:38,596 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 17:19:30,835 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:19:30,860 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:19:30,879 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:19:30,881 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:19:30,884 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:19:30,892 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:19:35,669 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:35,671 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:40,067 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:40,067 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:41,398 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:41,399 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:41,420 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:41,420 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:42,966 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:19:42,972 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:19:42,987 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:42,988 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:42,994 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:19:42,994 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:19:42,996 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:19:43,000 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 17:19:45,095 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:45,096 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:45,118 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:45,119 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:52,457 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:52,458 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:52,475 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:52,476 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:23:31,544 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:23:31,571 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:23:31,587 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:23:31,588 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:23:31,590 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:23:31,596 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:23:34,830 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:23:34,831 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:23:38,021 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:23:38,026 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:23:38,036 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:23:38,042 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:23:40,109 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:23:40,110 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:23:40,132 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:23:40,133 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:34:29,355 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:34:29,383 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:34:29,409 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:34:29,410 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:34:29,420 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:34:29,420 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 17:34:40,580 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:34:40,626 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:35:59,838 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:35:59,839 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:35:59,870 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:35:59,870 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:36:04,482 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:36:04,513 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:36:04,526 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:36:04,526 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:36:04,547 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:36:04,551 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:36:12,031 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:36:12,034 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:36:12,049 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:36:12,050 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:36:12,053 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:36:12,056 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:36:13,095 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:36:13,099 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:36:13,114 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:36:13,115 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:36:13,120 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:36:13,122 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:36:18,744 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:36:18,781 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:36:20,263 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:36:20,294 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:40:22,621 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:40:22,643 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:40:22,658 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:40:22,660 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:40:22,667 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:40:22,669 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:40:26,342 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:40:26,431 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:40:28,115 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:40:28,142 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:43:05,746 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:43:05,767 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:43:05,784 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:43:05,785 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:43:05,796 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:43:05,796 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:43:10,276 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:43:10,388 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:51:44,360 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:51:44,384 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:51:44,400 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:51:44,401 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:51:44,408 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:51:44,409 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:51:47,893 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:51:47,917 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:53:25,635 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:53:25,654 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:53:25,669 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:53:25,671 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:53:25,677 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:53:25,679 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:53:29,988 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:53:30,012 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:55:30,769 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:55:30,791 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:55:30,806 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:55:30,807 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:55:30,815 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:55:30,815 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:55:34,177 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:55:34,189 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:57:39,727 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:57:39,751 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:57:39,775 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:57:39,776 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:57:39,784 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:57:39,786 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:57:46,387 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:57:46,462 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:58:46,328 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:58:46,360 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:58:46,376 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:58:46,378 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:58:46,392 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:58:46,392 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:58:50,389 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:58:50,415 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 18:00:31,644 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:00:31,666 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:00:31,689 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:00:31,690 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:00:31,700 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:00:31,701 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:00:37,214 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:00:37,328] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:08:21,030 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:08:21,052 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:08:21,070 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:08:21,071 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:08:21,080 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 18:08:21,083 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:08:26,927 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:08:27,071] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:08:35,154 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:08:35,162 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:08:35,170 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:08:35,173 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:13:07,213 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:13:07,236 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:13:07,254 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:13:07,255 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:13:07,266 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:13:07,267 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:13:15,697 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:13:15,826] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:13:27,413 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:13:27,421 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:13:27,435 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:13:27,437 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:21:47,092 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:21:47,118 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:21:47,133 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:21:47,133 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:21:47,145 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:21:47,145 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:21:51,402 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:21:51,512] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:31:01,018 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:31:01,043 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:31:01,075 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:31:01,075 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:31:01,085 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:31:01,086 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:31:07,421 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:31:07,553] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:36:41,531 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:36:41,554 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:36:41,569 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:36:41,569 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:36:41,582 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:36:41,583 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:36:46,066 [DEBUG] → REQUEST GET / args={'message': ''} form=[]
2025-07-08 18:36:46,079 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:36:46,103 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:36:46,104 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:36:46,108 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:36:46,110 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:36:50,873 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:36:50,878 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:36:50,934 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:36:50,941 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:37:04,824 [DEBUG] → REQUEST GET / args={'message': ''} form=[]
2025-07-08 18:37:04,829 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:37:04,851 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:37:04,852 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:37:04,855 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:37:04,855 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:37:04,864 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 18:37:04,867 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:37:09,697 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:37:09,753 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:37:09,951] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:39:06,521 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:39:06,544 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:39:06,560 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:39:06,563 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:39:06,571 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:39:06,572 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:39:12,903 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:39:12,952 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:39:13,057] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:40:02,169 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:40:02,190 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:40:02,207 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:40:02,208 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:40:02,214 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 18:40:02,215 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:40:07,437 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:40:07,474 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:40:07,588] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:40:10,425 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:40:10,434 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:40:10,445 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:40:10,447 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:43:14,669 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:43:14,703 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:43:14,765 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:43:14,768 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:43:14,787 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:43:14,788 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:43:19,583 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:43:19,661 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:43:19,782] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:48:01,909 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:48:01,941 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:48:01,967 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:48:01,970 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:48:01,989 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:48:01,990 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:48:07,347 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:48:07,461 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-08 18:50:27,692 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:50:27,734 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:50:27,787 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:50:27,790 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:50:27,807 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:50:27,810 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:50:30,767 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:50:30,771 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:50:30,797 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:50:30,804 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:50:30,809 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:50:30,818 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:50:36,859 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:50:36,954 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:50:37,207] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:52:38,750 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:52:38,796 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:52:39,013 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:52:39,015 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:57:43,736 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:57:43,780 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:57:43,829 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:57:43,835 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:57:43,853 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:57:43,855 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:57:49,661 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:57:49,777 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:57:50,927] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:58:33,644 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:58:33,666 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:58:33,679 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:58:33,683 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 19:01:23,863 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 19:01:23,906 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 19:01:23,982 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 19:01:23,995 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 19:01:24,000 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 19:01:24,011 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 19:01:29,496 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 19:01:29,592 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 19:01:29,990] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 19:08:07,321 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 19:08:07,351 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 19:08:07,398 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 19:08:07,411 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 19:08:07,432 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 19:08:07,447 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 19:08:13,333 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 19:08:13,437 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 19:08:13,771] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:06:03,350 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:06:03,355 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:06:03,357 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:06:03,374 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:06:04,388 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:06:04,397 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:06:04,444 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:06:04,445 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:06:04,465 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:06:04,480 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 21:06:04,505 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:06:04,525 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:06:08,620 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:06:08,715 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:06:08,824] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:08:10,869 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:08:10,897 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:08:10,927 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:08:10,940 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:08:10,954 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:08:10,962 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:08:15,367 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:08:15,377 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:08:15,386 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:08:15,387 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:08:21,480 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:08:21,590 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:08:21,983] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:12:37,260 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:12:37,299 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:12:37,341 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:12:37,358 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:12:37,360 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:12:37,372 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:12:44,599 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:12:44,715 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:12:45,139] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:13:41,960 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:13:41,981 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:13:42,020 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:13:42,022 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:15:22,361 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:15:22,400 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:15:22,452 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:15:22,469 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:15:22,485 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:15:22,496 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 21:17:14,998 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:17:15,117 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:17:15,496] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:17:15,915 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:17:15,941 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:17:15,945 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:17:15,946 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:33:14,353 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:33:14,393 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:33:14,456 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:33:14,467 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 21:33:14,473 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:33:14,483 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:33:21,115 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:33:21,123 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:33:21,137 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:33:21,138 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:33:24,251 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:33:24,368 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:33:24,887] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:35:38,707 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:35:38,751 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:35:38,805 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:35:38,818 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:35:38,819 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:35:38,826 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:35:45,642 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:35:45,651 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:35:45,656 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:35:45,658 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:35:47,040 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:35:47,163 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:35:47,652] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:48:57,003 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:48:57,036 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:48:57,103 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:48:57,118 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:48:57,151 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:48:57,160 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 21:49:06,912 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:49:06,976 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:49:07,325] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 21:56:52,333 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:56:52,404 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:56:52,480 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:56:52,509 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:56:52,580 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:56:52,599 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 21:56:56,522 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:56:56,615 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:56:57,061] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:04:17,344 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:04:17,354 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:04:17,356 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:04:17,358 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:09:53,219 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:09:53,245 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:09:53,272 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:09:53,282 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:09:53,722 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:09:53,736 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:10:06,024 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:10:06,057 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:10:06,223] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:14:04,697 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:14:04,732 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:14:04,776 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:14:04,792 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:14:04,793 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:14:04,802 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:14:10,846 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:14:10,896 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:14:11,086] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:24:57,019 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:24:57,210 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:24:57,249 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:24:57,320 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:24:57,324 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:24:57,346 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:25:02,737 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:25:02,786 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:25:03,049] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:25:34,291 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:25:34,295 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:25:34,296 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:25:34,322 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:25:36,575 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:25:36,583 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:25:36,596 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:25:36,597 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:36:39,677 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:36:39,681 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:36:39,708 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:36:39,710 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:36:39,711 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:36:39,716 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 22:36:40,304 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:36:40,315 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:36:43,973 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:36:44,018 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:36:44,128] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:52:22,407 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:52:22,430 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:52:22,445 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:52:22,458 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:52:22,517 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:52:22,521 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 22:52:25,952 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:52:25,961 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:52:25,962 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:52:25,966 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:52:27,257 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:52:27,302 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:52:27,444] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:03:36,998 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:03:37,027 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:03:37,044 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:03:37,055 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:03:37,376 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:03:37,380 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 23:03:43,177 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:03:43,219 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:03:43,330] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:07:55,235 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:07:55,261 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:07:55,279 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:07:55,287 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:07:55,425 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:07:55,453 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:08:14,521 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:08:14,552 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:08:14,570 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:08:14,578 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:08:14,975 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:08:14,988 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:08:20,545 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:08:20,618 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:08:20,895] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:08:22,405 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:08:22,411 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:08:22,438 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:08:22,439 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:08:30,255 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:08:30,259 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:08:30,300 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:08:30,306 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 23:08:30,314 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:08:30,315 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:08:30,446 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:08:30,458 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 23:08:35,661 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:08:35,709 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:08:35,746] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:18:49,644 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:18:49,669 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:18:49,689 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:18:49,702 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:18:50,072 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:18:50,109 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:18:58,123 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:18:58,160 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:18:58,315] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:33:55,369 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:33:55,394 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:33:55,409 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:33:55,418 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:33:55,805 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:33:55,815 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:33:59,192 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:33:59,224 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:33:59,318] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:38:50,698 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:38:50,706 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:38:50,825 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:38:50,826 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:39:05,586 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:39:05,587 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:46:30,564 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:46:30,583 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:46:30,601 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:46:30,608 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:46:30,815 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:46:30,851 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:46:36,239 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:46:36,267 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:46:36,358] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:54:22,395 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:54:22,418 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:54:22,464 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:54:22,474 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:54:22,565 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:54:22,576 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:54:24,835 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:54:24,839 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:54:24,869 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:54:24,878 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:54:24,881 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:54:24,905 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:54:26,421 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:54:26,425 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:54:26,440 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:54:26,444 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:54:26,446 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:54:26,451 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:54:30,095 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:54:30,131 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:54:30,234] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:59:43,127 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:59:43,136 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:59:43,263 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:59:43,264 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:09:12,115 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:09:12,138 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:09:12,161 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:09:12,172 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:09:12,542 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:09:12,565 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:09:36,265 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:09:36,293 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:09:36,378] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 00:09:40,163 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:09:40,170 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 00:09:40,171 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:09:40,171 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:15:04,522 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:15:04,588 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:15:04,678 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:15:04,708 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:15:04,764 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:15:04,784 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-09 00:15:07,932 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:15:08,031 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:15:08,451] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 00:15:14,101 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:15:14,108 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:15:14,125 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 00:15:14,126 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:27:22,007 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:27:22,043 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:27:22,088 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:27:22,101 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:27:22,157 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:27:22,173 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:27:26,590 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:27:26,703 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:27:27,395] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 00:27:31,538 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:27:31,544 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:27:31,573 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 00:27:31,574 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:37:32,776 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:37:32,819 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:37:32,888 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:37:32,901 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:37:32,965 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:37:32,979 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:37:35,524 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:37:35,529 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:37:35,553 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:37:35,560 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:37:35,565 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:37:35,574 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:37:39,680 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:37:39,769 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:37:40,139] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:09:26,221 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:09:26,248 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:09:26,272 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:09:26,281 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:09:26,349 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:09:26,356 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:09:34,750 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:09:34,811 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:09:35,006] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:20:25,100 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:20:25,141 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:20:25,192 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:20:25,207 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:20:25,283 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:20:25,304 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:20:30,030 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:20:30,153 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-09 10:24:24,092 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:24:24,133 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:24:24,193 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:24:24,207 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:24:24,294 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:24:24,312 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:24:30,922 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:24:30,931 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:24:30,940 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 10:24:30,941 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 10:24:32,180 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:24:32,271 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:24:32,728] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:29:13,425 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:29:13,511 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:29:13,732] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-09 10:35:21,244] ERROR: ❌ Errore di rete con Ollama: HTTPConnectionPool(host='127.0.0.1', port=11434): Read timed out. (read timeout=360)
2025-07-09 10:36:40,660 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:36:40,688 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:36:40,735 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:36:40,748 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:36:40,853 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:36:40,871 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:36:47,089 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:36:47,153 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:36:47,356] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:48:21,349 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:48:21,377 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:48:21,420 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:48:21,430 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:48:21,488 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:48:21,501 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:48:27,191 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:48:27,214 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 126, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 412, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 381, in build_pipeline
    builder.add_conditional_edges("ChatFeedback", path=should_continue_after_refine)
NameError: name 'should_continue_after_refine' is not defined
2025-07-09 10:48:27,242 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-09 10:48:27,242 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-09 10:50:07,566 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:50:07,597 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:50:07,619 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:50:07,631 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:50:07,878 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:50:07,946 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:50:12,825 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:50:12,889 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:50:13,072] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 11:03:18,410 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 11:03:18,437 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 11:03:18,468 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 11:03:18,480 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 11:03:18,550 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 11:03:18,558 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 11:03:22,534 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 11:03:22,568 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 11:03:22,771] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 11:12:39,733 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-09 11:12:39,988] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 11:14:11,612 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 10:55:59,052 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 10:55:59,082 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 10:55:59,100 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 10:55:59,109 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 10:55:59,113 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 10:55:59,120 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 10:56:02,821 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 10:56:02,857 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 10:59:56,168 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 10:59:56,226 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 10:59:56,247 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 10:59:56,264 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 10:59:56,625 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 10:59:56,660 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:00:02,341 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:00:01,533 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 11:04:11,655 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:04:11,698 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:04:11,731 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:04:11,741 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:04:11,743 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:04:11,748 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:04:21,237 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:04:21,304 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 11:12:18,330 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:12:18,364 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:12:18,404 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:12:18,418 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:12:18,429 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:12:18,460 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:12:23,669 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:12:23,720 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:12:23,845] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:12:46,890 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:12:46,899 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:12:46,912 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:12:46,913 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:12:48,110 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:12:48,115 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:12:48,152 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:12:48,153 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:12:48,154 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:12:48,161 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 11:12:48,192 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:12:48,204 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:12:52,764 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:12:52,824 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:12:52,864] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:18:55,944 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:18:55,968 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:18:55,989 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:18:56,000 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:18:56,012 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:18:56,020 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:18:59,889 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:18:59,932 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:19:00,074] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:20:15,089 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:20:15,119 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:20:15,142 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:20:15,155 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:20:15,163 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:20:15,172 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:20:19,687 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:20:19,730 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:20:19,866] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:20:29,642 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:20:29,654 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:20:29,663 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:20:29,664 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:20:31,712 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:20:31,718 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:20:31,769 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:20:31,770 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:20:31,772 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:20:31,778 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 11:20:31,804 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:20:31,814 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:20:32,979 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 11:20:32,983 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 11:20:35,885 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:20:35,947 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:20:35,990] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:25:40,982 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:25:41,012 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:25:41,030 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:25:41,039 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:25:41,055 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:25:41,067 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:25:46,134 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:25:46,181 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:25:46,480] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:28:04,476 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:28:04,502 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:28:04,520 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:28:04,532 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:28:04,983 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:28:05,010 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:28:07,754 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:28:07,810 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 11:28:52,725 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:28:52,760 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:28:52,792 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:28:52,803 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:28:53,193 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:28:53,235 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:28:56,763 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:28:56,807 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:28:56,940] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:35:40,210 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:35:40,235 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:35:40,252 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:35:40,265 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:35:40,278 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:35:40,292 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:35:43,751 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:35:43,880 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:35:44,158] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:38:54,173 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:38:54,208 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:38:54,254 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:38:54,269 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:38:54,270 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:38:54,282 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:38:59,598 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:38:59,670 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:38:58,815] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:49:18,011 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:49:18,040 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:49:18,083 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:49:18,100 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:49:18,101 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:49:18,110 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:49:22,531 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:49:22,573 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:49:22,752] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:49:22,908] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 11:50:24,640 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:50:24,666 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:50:24,696 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:50:24,705 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:50:24,715 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:50:24,723 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:50:28,173 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:50:28,216 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:50:28,387] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:58:05,081 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:58:05,110 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:58:05,153 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:58:05,167 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:58:05,170 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:58:05,175 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:58:10,810 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:58:10,854 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:58:10,974] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:58:11,114] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 11:58:16,775 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 11:58:16,900] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:58:16,944] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
[2025-07-10 11:58:16,968] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:58:17,005] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 11:58:17,106 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 11:58:17,636 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:58:17,718 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 12:03:00,635 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:03:00,669 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:03:00,715 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:03:00,725 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:03:00,736 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:03:00,744 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:03:10,223 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:03:10,290 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:03:10,397] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:09:22,232] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:29:13,215 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:29:13,243 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:29:13,263 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:29:13,272 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:29:13,662 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:29:13,674 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:29:17,453 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:29:17,495 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:29:17,753] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:29:17,810] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:29:17,844] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:29:17,888] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:31:26,408 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:31:26,429 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:31:26,447 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:31:26,456 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:31:26,896 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:31:26,921 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:31:30,931 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:31:30,970 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:31:31,112] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:31:31,176] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:32:29,249 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:32:29,274 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:32:29,292 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:32:29,302 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:32:29,315 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:32:29,323 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:32:32,834 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:32:32,866 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:32:32,997] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:32:33,046] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 12:33:18,445 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:33:18,471 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:33:18,489 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:33:18,497 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:33:18,500 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:33:18,511 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:33:22,044 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:33:22,084 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:33:22,192] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:33:22,243] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:34:35,837 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:34:35,945] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:35,990] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:34:36,025] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:36,060] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:34:36,113 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 12:34:36,654 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:34:36,689 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:34:36,719] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:36,757] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:34:36,783] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:36,821] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:35:11,389 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:35:11,490] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:11,524] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:35:11,547] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:11,581] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:35:11,644 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 12:35:12,177 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:35:12,214 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:35:12,249] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:12,284] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:35:12,308] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:12,344] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:35:39,856 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:35:39,883 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:35:39,900 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:35:39,910 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:35:40,451 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:35:40,465 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:35:45,626 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:35:45,685 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:35:44,713] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:44,764] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:35:44,797] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:44,835] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:36:39,872 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:36:39,895 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:36:39,913 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:36:39,921 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:36:40,302 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:36:40,332 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:36:43,773 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:36:43,823 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:36:43,951] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:36:43,998] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:36:44,035] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:36:44,073] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:37:58,159 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:37:58,190 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:37:58,215 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:37:58,228 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:37:58,230 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:37:58,234 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:38:03,992 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:38:04,043 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:38:04,192] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:38:04,242] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 12:48:00,307 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:48:00,334 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:48:00,350 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:48:00,359 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:48:00,796 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:48:00,816 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 12:48:14,217 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:48:14,499] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:30,190 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:48:30,247 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:48:30,283] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:30,874 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:48:30,911 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:48:30,943] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:31,119 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:48:31,186 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:48:31,223] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:42,875 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:48:42,880 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:48:42,933 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:48:42,937 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:48:42,941 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:48:42,945 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:49:11,790 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:49:11,823 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:49:11,869 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:49:11,883 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:49:11,884 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:49:11,892 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:49:15,960 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:49:16,024 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:49:16,246] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:59:21,435 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:59:21,548] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 13:06:20,393] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 13:12:08,330] ERROR: ❌ Errore di rete con Ollama: HTTPConnectionPool(host='127.0.0.1', port=11434): Read timed out. (read timeout=360)
2025-07-10 13:12:09,144 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 13:12:10,162 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 13:12:10,408 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 13:12:12,071] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:12:52,623 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:12:52,695 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:12:52,793 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:12:52,818 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:12:52,822 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 14:12:52,842 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:13:03,680 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:13:04,336] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:13:13,656 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:13:13,813 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:13:13,906] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:03,530 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:20:03,570 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:20:03,616 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:20:03,634 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:20:03,648 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:20:03,660 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:20:10,599 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:11,393] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:11,472] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:11,754 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:11,769 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:11,902 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:11,995] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:12,069] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:16,873 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:17,199] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:17,267] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:17,482 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:17,493 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:17,568 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:17,673] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:17,748] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:27,086 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:27,453] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:27,512] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:27,519 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:27,605 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:27,670] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:27,744] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:27,747 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:27,759 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:27,867 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:27,948] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:28,020] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:33,547 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:20:33,549 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 14:20:33,550 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 14:20:33,560 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:20:34,134 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:34,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:34,585] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:34,786 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:34,800 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:34,902 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:35,042] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:35,118] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:47,246 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:47,605] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:47,668] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:47,900 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:47,917 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:48,087 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:48,195] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:48,271] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:50,016 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:50,229 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:50,373] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:50,456] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:52,294 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,484 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,491 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:52,576 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:52,646 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,767 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:52,828 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,981 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:53,017 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:53,105 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,173] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:53,191 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:20:53,251] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:53,275 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,335] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:53,382 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:20:53,424] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:53,464 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:53,552 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:20:53,608] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:53,630 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,674] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:53,745] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:21:01,301 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:21:01,560 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:21:01,693] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:21:01,769] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:21:45,510 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:21:45,551 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:21:45,618 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:21:45,634 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:21:45,668 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:21:45,684 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:21:51,456 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:21:51,590 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:21:52,100] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:21:52,176] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:17,613 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:22:17,950] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:18,027] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:18,317 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:22:18,333 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:22:18,460 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:22:18,589] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:18,662] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:26,045 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:22:26,255 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:22:26,398] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:26,465] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:29,811 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:22:30,117] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:30,180] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
[2025-07-10 14:22:30,248] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:30,315] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:30,426 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:22:30,967 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:22:31,135 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:22:31,252] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:31,320] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
[2025-07-10 14:22:31,366] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:31,429] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:23:07,480 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:23:07,768] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:23:07,835] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:23:08,096 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:23:08,109 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:23:08,287 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:23:08,478] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:23:08,549] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:23:35,123 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:23:35,248 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:23:35,442] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:23:35,505] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:04,248 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:25:04,296 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:25:04,353 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:25:04,368 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:25:04,395 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:25:04,410 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:25:08,133 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:08,135 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 14:25:11,831 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:11,982 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:25:12,557] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:12,628] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:21,722 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:25:22,058] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:22,122] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:22,324 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:25:22,334 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:22,413 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:25:22,528] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:22,594] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:23,521 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:23,686 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:23,711 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:23,785 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:23,841 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,011 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,016 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,131 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,168 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,290 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,359 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,534 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,547 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,610 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,690 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,814 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,928 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:25,104 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:25:25,209] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:25,278] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:29:18,505 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:29:18,581 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:29:18,657 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:29:18,677 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:29:18,678 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:29:18,693 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:29:24,821 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:29:25,351] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:29:25,424] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:29:25,667 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:29:25,680 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:29:25,772 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:29:25,872] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:29:25,942] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:30:39,582 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:30:39,624 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:30:39,666 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:30:39,683 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:30:39,696 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:30:39,711 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:30:48,372 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:30:49,227] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:30:49,300] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:30:49,615 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:30:49,638 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:30:49,656 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 146, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
NameError: name 'reset' is not defined
2025-07-10 14:30:49,694 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-10 14:30:49,696 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-10 14:31:11,407 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:31:11,762] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:31:11,826] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:31:12,042 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:31:12,055 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:31:12,067 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 146, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
NameError: name 'reset' is not defined
2025-07-10 14:31:12,075 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-10 14:31:12,076 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-10 14:31:12,818 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:31:12,838 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 146, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
NameError: name 'reset' is not defined
2025-07-10 14:31:12,852 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-10 14:31:12,853 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-10 14:37:53,030 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:37:53,067 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:37:53,134 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:37:53,149 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:37:53,152 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:37:53,166 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:37:58,941 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:37:59,057 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:37:59,423] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:37:59,498] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:03,643 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:38:03,923] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:03,994] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:04,300 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:38:04,316 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:04,447 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:04,578] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:04,650] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:05,745 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:05,939 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:06,079] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:06,150] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:08,184 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:38:08,193 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:38:08,233 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:38:08,235 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:38:08,245 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:38:08,248 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:38:22,819 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:38:23,177] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:23,245] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:23,499 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:38:23,518 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:23,676 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:23,790] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:23,861] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:28,325 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:38:28,632] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:28,693] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:28,903 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:38:29,444 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:29,635 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:29,847] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:29,909] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:39:52,345 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:39:52,372 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:39:52,399 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:39:52,414 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:39:52,427 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:39:52,440 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:40:00,389 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:40:01,140] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:40:01,218] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:40:01,539 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:40:01,554 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:40:01,669 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:40:01,810] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:40:01,874] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:46:33,075 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:46:33,116 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:46:33,177 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:46:33,191 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:46:33,204 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:46:33,219 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 14:46:37,486 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:46:37,613 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:46:38,002] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:46:38,072] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:46:41,226 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:46:41,571] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:46:41,638] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:46:41,943 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:46:41,960 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:46:42,110 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:46:42,313] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:46:42,386] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:48:29,069 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:48:29,114 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:48:29,170 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:48:29,187 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:48:29,489 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:48:29,509 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:48:34,017 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:48:34,793] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:48:34,889] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:48:35,191 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:48:35,207 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:48:35,338 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:48:35,534] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:48:35,604] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:50:28,316 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:50:28,379 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:50:28,478 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:50:28,504 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:50:28,507 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:50:28,527 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:50:33,993 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:34,108 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:34,304] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:34,379] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:50:37,838 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:50:38,034] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:38,101] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:50:38,190 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:50:38,204 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:50:38,330 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:38,385] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:38,461] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:39,385 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:39,504 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:39,556 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:39,654 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:39,711] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:50:39,774 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:50:39,776] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:39,889 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:40,016] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:40,090] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:40,497 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:40,670 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:40,700 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:40,774 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:40,838 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:40,922 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:40,989] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:50:41,010 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:50:41,100] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:41,162 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,163 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,263 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,334 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,431 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,488 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,604 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,643 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,730 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,794 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,900 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,920 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,022 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,055 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,244 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,275 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,310 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,363 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,422 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,445 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,545 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:42,634] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:42,701] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:53:19,055 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:53:19,107 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:53:19,181 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:53:19,202 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:53:19,204 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:53:19,219 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:53:28,613 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:53:29,395] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:53:29,462] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:53:29,712 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:53:29,728 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:53:29,856 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:53:30,046] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:53:30,114] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:55:48,024 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:55:48,090 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:55:48,192 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:55:48,220 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:55:48,226 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:55:48,248 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:55:56,026 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:55:57,126] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:00:03,654 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:00:03,956] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:00:09,033 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:00:09,046 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:00:09,119 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:00:09,123 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:00:09,136 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:00:09,139 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:00:10,957 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 15:00:10,961 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:00:12,295 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 15:00:12,299 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:00:14,294 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 15:00:14,299 [DEBUG] ← RESPONSE POST /message status=400
2025-07-10 15:00:14,314 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 15:00:14,318 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:01:06,344 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:01:06,391 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:01:06,435 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:01:06,449 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:01:06,455 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:01:06,470 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:01:13,212 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:01:14,070] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:02:28,264 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:02:28,286 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 15:02:28,289 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 15:02:28,298 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:02:40,774 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:02:40,790 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:02:40,885 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 15:02:40,889 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 15:02:40,894 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:02:40,924 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 15:02:40,948 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:02:40,978 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 15:02:51,008 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:02:51,184 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:02:51,445] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:06:45,361 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:06:45,494 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:06:45,575] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:08:02,218 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:08:02,257 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:08:02,294 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:08:02,309 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:08:02,315 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:08:02,326 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:08:07,628 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:08:07,775 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:08:08,540] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:30:36,662 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:30:36,823] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:36:33,468 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 15:36:34,787 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:36:34,898 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:36:35,019] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:39:39,200 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:39:39,243 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:39:39,289 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:39:39,306 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:39:39,316 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:39:39,328 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:39:40,915 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:39:40,920 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:39:40,949 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:39:40,958 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:39:40,962 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:39:40,975 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:39:49,010 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:39:49,520] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:40:00,097 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:40:00,300] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:40:00,921 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:40:01,088] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:40:03,303 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:40:03,353 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:40:03,397] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 15:46:03,495] ERROR: ❌ Errore di rete con Ollama: HTTPConnectionPool(host='127.0.0.1', port=11434): Read timed out. (read timeout=360)
2025-07-10 15:53:27,668 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 15:53:27,680 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 15:53:27,757 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:53:27,836] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:57:32,385 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:57:32,410 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:57:32,428 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:57:32,435 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:57:32,446 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:57:32,454 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:57:37,049 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 15:57:37,053 [DEBUG] ← RESPONSE POST /message status=400
2025-07-10 15:57:37,061 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 15:57:37,076 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:57:43,447 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:57:43,560 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:57:43,994] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:01:49,501 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:01:49,533 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:01:49,583 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:01:49,593 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:01:49,640 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:01:49,648 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 16:01:56,036 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:01:56,198 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:01:56,473] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:14:52,203 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 16:14:52,324] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:21:55,323 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 16:21:56,733 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:21:56,783 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:21:56,861] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:29:27,953 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:29:27,983 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:29:28,021 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:29:28,029 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:29:28,036 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:29:28,044 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 16:29:30,593 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:29:30,596 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:29:30,611 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:29:30,617 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:29:30,619 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:29:30,627 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 16:29:34,350 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:29:34,380 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:29:34,563] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:35:51,297 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 16:35:51,395] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:42:52,889 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 16:42:53,742 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:42:53,824 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:42:53,866] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:49:53,734 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:49:53,762 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:49:53,778 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:49:53,787 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:49:53,803 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:49:53,811 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 16:49:57,402 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 16:49:57,410 [DEBUG] ← RESPONSE POST /message status=400
2025-07-10 16:49:57,418 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 16:49:57,420 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:00,826 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:00,829 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:02,178 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:02,181 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:18,976 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:18,980 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:46,224 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 16:50:46,500] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:50:48,546 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:48,593 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:50:48,635] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:53:23,755 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:53:23,762 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 16:53:23,763 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 16:53:23,773 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:53:28,338 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:53:28,361 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:53:28,376 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 16:53:28,377 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 16:53:28,388 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:53:28,397 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 16:53:28,427 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:53:28,436 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 16:53:32,976 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:53:33,023 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:53:33,191] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 17:13:09,357 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 17:13:09,478 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 17:26:43,813 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 17:26:43,834 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 17:26:43,854 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 17:26:43,862 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 17:26:43,874 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 17:26:43,882 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 17:26:48,888 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 17:26:48,952 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 17:26:49,128] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 17:50:54,646 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 17:50:54,679 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 17:50:54,703 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 17:50:54,715 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 17:50:54,726 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 17:50:54,731 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 17:50:58,361 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 17:50:58,395 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 17:50:58,641] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 17:55:57,805 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 17:55:57,829 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 17:55:57,845 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 17:55:57,854 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 17:55:57,861 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 17:55:57,867 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 17:56:06,000 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 17:56:06,093 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 17:56:06,310] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 18:09:38,197 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 18:09:38,323 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 18:23:45,776 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 18:23:45,804 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 18:23:45,819 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 18:23:45,832 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 18:23:45,842 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 18:23:45,853 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 18:23:49,354 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 18:23:49,395 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 18:23:49,560] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 18:34:06,475 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 18:34:06,573 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 18:35:54,892 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 18:35:55,048 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 18:36:12,941 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 18:36:12,973 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 18:36:13,022 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 18:36:13,033 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 18:36:13,043 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 18:36:13,055 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 18:36:14,727 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 18:36:14,730 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 18:36:14,745 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 18:36:14,750 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 18:36:14,752 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 18:36:14,759 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 18:36:18,890 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 18:36:18,923 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 18:36:19,089] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 18:46:56,322 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 18:46:56,482] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 11:49:50,215 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:49:50,220 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:49:50,236 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:49:50,238 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-11 11:49:50,339 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:49:50,340 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-11 11:49:50,419 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-11 11:49:50,419 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-11 11:50:03,442 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:50:03,442 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:50:03,452 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 11:50:03,452 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 11:50:20,487 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:50:20,488 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/home/giova/PDDL_LLM-1/venv/lib/python3.12/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/giova/PDDL_LLM-1/venv/lib/python3.12/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/giova/PDDL_LLM-1/venv/lib/python3.12/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/giova/PDDL_LLM-1/venv/lib/python3.12/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/giova/PDDL_LLM-1/PROGETTOIAPDDL/routes/pipeline_chat.py", line 150, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/giova/PDDL_LLM-1/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 466, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/giova/PDDL_LLM-1/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 406, in build_pipeline
    builder = StateGraph(PipelineState, stateful=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: StateGraph.__init__() got an unexpected keyword argument 'stateful'
2025-07-11 11:50:20,489 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 11:50:20,489 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 11:53:44,746 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:53:44,752 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:53:44,771] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 11:53:44,780] ERROR: ❌ HTTP Error da Ollama (404): {"error":"model 'llama3:8b-instruct-q5_K_M' not found"}
[2025-07-11 11:53:44,789] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 11:53:44,792] ERROR: ❌ HTTP Error da Ollama (404): {"error":"model 'llama3:8b-instruct-q5_K_M' not found"}
2025-07-11 11:55:41,333 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:55:41,339 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:55:41,362] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
[2025-07-11 11:59:05,426] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 12:17:50,901 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 12:17:50,908 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 12:17:50,934] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 12:22:38,271 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 12:22:38,278 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 12:22:38,303] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 12:29:08,905 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 12:29:08,911 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 12:29:08,930] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 12:29:18,154 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 12:29:18,155 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 12:29:20,426 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 12:29:20,437 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 12:29:20,483 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:29:20,486 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 12:29:20,490 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 12:29:20,491 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:29:20,512 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 12:29:20,513 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-11 12:29:35,740 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 12:29:35,740 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 12:29:35,780 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 12:29:35,781 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 12:29:35,801 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:29:35,803 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 12:29:35,804 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:29:35,805 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 12:30:34,278 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 12:30:34,284 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 12:30:34,296 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:30:34,298 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:30:34,345 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 12:30:34,346 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 12:44:07,194 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 12:44:07,200 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 12:44:07,213 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:44:07,215 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:44:07,238 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 12:44:07,239 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 12:44:08,850 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:44:08,850 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:44:08,858 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 12:44:08,859 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 12:51:18,148 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 12:51:18,155 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 12:51:18,175 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 12:51:18,176 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 12:51:18,177 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:51:18,182 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:51:18,194 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 12:51:18,195 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-11 12:53:06,390 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 12:53:06,397 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 12:53:06,507 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:53:06,511 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:53:06,531 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 12:53:06,531 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-11 12:53:06,575 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-11 12:53:06,575 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-11 12:53:10,580 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 12:53:10,580 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 12:53:10,602 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 12:53:10,603 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 12:53:16,986 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 12:53:16,994 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 12:53:17,019] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 14:35:54,223 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 14:35:54,229 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 14:35:54,243 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:35:54,248 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:35:54,268 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 14:35:54,268 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 14:35:54,322 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-11 14:35:54,322 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-11 14:35:57,385 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:35:57,395 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:35:57,424] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 14:41:19,448 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:41:19,455 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:41:19,488] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 14:44:37,202 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:44:37,214 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:44:37,224] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 14:44:50,859 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:44:50,865 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:44:50,885] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
2025-07-11 15:00:27,435 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:00:27,443 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 15:00:27,469] INFO: 📤 Invio prompt a Ollama con modello: devstral:24b
