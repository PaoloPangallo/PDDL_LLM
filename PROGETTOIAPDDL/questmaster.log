

Driver aborting after translate
INFO     Planner time: 0.09s

2025-06-29 14:46:45,390 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 634, in parse_task\n    task_name, task_domain_name, task_requirements, objects, init, goal, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 782, in parse_task_pddl\n    yield parse_init(context, init)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 617, in parse_init\n    atom = pddl.Atom(fact[0], fact[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 14:46:45,441 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 14:46:45,442 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "has-item",
    "open"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 14:46:45,446 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 14:46:45,452 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 14:48:35,075 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 14:48:35,081 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 14:48:35,082 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 14:48:35,093 [ERROR] ❌ Fallita la raffinazione automatica: ❌ DOMAIN block not found.
2025-06-29 14:48:35,127 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 14:48:35,132 [INFO] 127.0.0.1 - - [29/Jun/2025 14:48:35] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 14:48:35,150 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-144432-9cc722'} form_keys=[]
2025-06-29 14:48:35,254 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 14:48:35,327 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 14:48:35,328 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "has-item",
    "open"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 14:48:35,339 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 14:48:35,342 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 14:49:42,161 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 14:49:42,210 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-144432-9cc722
2025-06-29 14:49:42,215 [INFO] ✅ Riflessione completata.
2025-06-29 14:49:42,240 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 14:49:42,241 [INFO] 127.0.0.1 - - [29/Jun/2025 14:49:42] "GET /result?session=the_hero_must_reach_the_tower_-20250629-144432-9cc722 HTTP/1.1" 200 -
2025-06-29 14:49:42,296 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 14:49:42,300 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 14:49:42,314 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 14:49:42,314 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 14:49:42,315 [INFO] 127.0.0.1 - - [29/Jun/2025 14:49:42] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 14:49:42,316 [INFO] 127.0.0.1 - - [29/Jun/2025 14:49:42] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 14:54:22,953 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 14:54:22,956 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 14:54:22,957 [INFO] 127.0.0.1 - - [29/Jun/2025 14:54:22] "GET / HTTP/1.1" 200 -
2025-06-29 14:54:22,972 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 14:54:22,973 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 14:54:22,988 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 14:54:22,989 [INFO] 127.0.0.1 - - [29/Jun/2025 14:54:22] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 14:54:22,990 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 14:54:22,990 [INFO] 127.0.0.1 - - [29/Jun/2025 14:54:22] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 14:54:25,399 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 14:54:25,783 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 14:54:25,786 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 14:56:40,132 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 14:56:40,159 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 14:56:40,159 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 14:56:40,160 [WARNING] ⚠️ Generazione fallita: PDDL non valido.
2025-06-29 14:56:40,197 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 14:56:40,198 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 14:56:40,240 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-145425-38a75b'} form_keys=[]
2025-06-29 14:56:40,294 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 14:56:40,294 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "GET /result?session=the_hero_must_reach_the_tower_-20250629-145425-38a75b HTTP/1.1" 200 -
2025-06-29 14:56:40,365 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 14:56:40,367 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 14:56:40,372 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 14:56:40,372 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 14:56:40,375 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 14:56:40,376 [INFO] 127.0.0.1 - - [29/Jun/2025 14:56:40] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:23:10,475 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 15:23:10,769 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 15:23:10,780 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 15:27:08,080 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:27:08,951 [INFO] ⏱️ Planner terminato in 0.76s (exit code: 30)
2025-06-29 15:27:08,952 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/problem.pddl con lazy_greedy([ff()]) (dominio: simple_maze)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/problem.pddl --sas-file output.sas
Parsing...
translate exit code: 30

Driver aborting after translate
INFO     Planner time: 0.15s

2025-06-29 15:27:08,953 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 630, in parse_task\n    domain_name, domain_requirements, types, type_dict, constants, predicates, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 733, in parse_domain_pddl\n    the_axioms, the_actions = parse_axioms_and_actions(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 569, in parse_axioms_and_actions\n    action = parse_action(context, entry, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 523, in parse_action\n    cost = parse_effects(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 332, in parse_effects\n    tmp_effect = parse_effect(context, alist, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 393, in parse_effect\n    effects.append(parse_effect(context, eff, type_dict, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 434, in parse_effect\n    return pddl.SimpleEffect(parse_literal(context, alist, {}, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 305, in parse_literal\n    return pddl.Atom(pred_id, alist[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 15:27:09,000 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 15:27:09,001 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 15:27:09,018 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 15:27:09,031 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 15:29:17,258 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:29:17,318 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-152310-eaf7bf/llm_suggestion.pddl
2025-06-29 15:29:17,340 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 15:29:17,349 [INFO] 127.0.0.1 - - [29/Jun/2025 15:29:17] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 15:29:17,381 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-152310-eaf7bf'} form_keys=[]
2025-06-29 15:29:17,441 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 15:29:17,479 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 15:29:17,480 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 15:29:17,493 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 15:29:17,496 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 15:31:22,508 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:31:22,517 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 15:31:22,518 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 15:31:22,536 [WARNING] ⚠️ Errore durante la riflessione automatica: ❌ DOMAIN block not found.
2025-06-29 15:31:22,556 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 15:31:22,557 [INFO] 127.0.0.1 - - [29/Jun/2025 15:31:22] "GET /result?session=the_hero_must_reach_the_tower_-20250629-152310-eaf7bf HTTP/1.1" 200 -
2025-06-29 15:31:22,623 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:31:22,628 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:31:22,644 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:31:22,646 [INFO] 127.0.0.1 - - [29/Jun/2025 15:31:22] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:31:22,647 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:31:22,648 [INFO] 127.0.0.1 - - [29/Jun/2025 15:31:22] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:51:37,480 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 15:51:38,028 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 15:51:38,035 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 15:53:47,740 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:53:47,771 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 15:53:47,772 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 15:53:47,773 [WARNING] ⚠️ Generazione fallita: PDDL non valido.
2025-06-29 15:53:47,824 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 15:53:47,830 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:47] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 15:53:47,848 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-155137-a65466'} form_keys=[]
2025-06-29 15:53:47,921 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 15:53:47,922 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:47] "GET /result?session=the_hero_must_reach_the_tower_-20250629-155137-a65466 HTTP/1.1" 200 -
2025-06-29 15:53:47,992 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:53:47,997 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:53:48,009 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:53:48,011 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:53:48,013 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:53:48,014 [INFO] 127.0.0.1 - - [29/Jun/2025 15:53:48] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:55:14,311 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 15:55:14,317 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 15:55:14,318 [INFO] 127.0.0.1 - - [29/Jun/2025 15:55:14] "GET / HTTP/1.1" 200 -
2025-06-29 15:55:14,344 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:55:14,345 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:55:14,349 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:55:14,351 [INFO] 127.0.0.1 - - [29/Jun/2025 15:55:14] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:55:14,353 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:55:14,354 [INFO] 127.0.0.1 - - [29/Jun/2025 15:55:14] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 15:55:16,736 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 15:55:16,812 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 15:55:16,815 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 15:56:14,920 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 15:56:14,938 [WARNING] ⚠️ Delimitatori non trovati: === DOMAIN START === / === DOMAIN END ===
2025-06-29 15:56:14,939 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 15:56:14,940 [WARNING] ⚠️ Generazione fallita: PDDL non valido.
2025-06-29 15:56:14,962 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 15:56:14,963 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:14] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 15:56:14,977 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-155516-32908e'} form_keys=[]
2025-06-29 15:56:15,015 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 15:56:15,016 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:15] "GET /result?session=the_hero_must_reach_the_tower_-20250629-155516-32908e HTTP/1.1" 200 -
2025-06-29 15:56:15,083 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 15:56:15,086 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 15:56:15,091 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 15:56:15,092 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:15] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 15:56:15,094 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 15:56:15,095 [INFO] 127.0.0.1 - - [29/Jun/2025 15:56:15] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 16:04:42,490 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 16:04:42,495 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 16:04:42,496 [INFO] 127.0.0.1 - - [29/Jun/2025 16:04:42] "GET / HTTP/1.1" 200 -
2025-06-29 16:04:42,518 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 16:04:42,519 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 16:04:42,526 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 16:04:42,527 [INFO] 127.0.0.1 - - [29/Jun/2025 16:04:42] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 16:04:42,529 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 16:04:42,530 [INFO] 127.0.0.1 - - [29/Jun/2025 16:04:42] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 16:04:44,806 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 16:04:44,896 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 16:04:44,900 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 16:07:47,003 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:07:47,531 [INFO] ⏱️ Planner terminato in 0.47s (exit code: 31)
2025-06-29 16:07:47,532 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/problem.pddl con lazy_greedy([ff()]) (dominio: robot-assembly)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/problem.pddl --sas-file output.sas
Parsing...
Error: Could not parse domain file: /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/domain.pddl
Reason: Tokens remaining after parsing: ( define ( function get-robots-at ?assembly-line ) ( all ( ?robot ) ( implies ( and ( eq ?robot ( type-of ?robot ) ) ( at-robot ?robot ?assembly-line ) ) true ) ) )
translate exit code: 31

Driver aborting after translate
INFO     Planner time: 0.09s

2025-06-29 16:07:47,533 [DEBUG] STDERR:

2025-06-29 16:07:47,563 [INFO] 🔁 LLM invoked with error: 
2025-06-29 16:07:47,565 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "assembled"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 16:07:47,573 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 16:07:47,575 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 16:09:32,355 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:09:32,410 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-160444-e2500e/llm_suggestion.pddl
2025-06-29 16:09:32,424 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 16:09:32,427 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 16:09:32,457 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-160444-e2500e'} form_keys=[]
2025-06-29 16:09:32,516 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 16:09:32,517 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "GET /result?session=the_hero_must_reach_the_tower_-20250629-160444-e2500e HTTP/1.1" 200 -
2025-06-29 16:09:32,603 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 16:09:32,604 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 16:09:32,612 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 16:09:32,613 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 16:09:32,614 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 16:09:32,614 [INFO] 127.0.0.1 - - [29/Jun/2025 16:09:32] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 16:24:33,937 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 16:24:34,512 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 16:24:34,522 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 16:27:49,130 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:27:49,901 [INFO] ⏱️ Planner terminato in 0.67s (exit code: 30)
2025-06-29 16:27:49,902 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/problem.pddl con lazy_greedy([ff()]) (dominio: my_domain)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/problem.pddl --sas-file output.sas
Parsing...
translate exit code: 30

Driver aborting after translate
INFO     Planner time: 0.23s

2025-06-29 16:27:49,903 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 630, in parse_task\n    domain_name, domain_requirements, types, type_dict, constants, predicates, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 733, in parse_domain_pddl\n    the_axioms, the_actions = parse_axioms_and_actions(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 569, in parse_axioms_and_actions\n    action = parse_action(context, entry, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 523, in parse_action\n    cost = parse_effects(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 332, in parse_effects\n    tmp_effect = parse_effect(context, alist, type_dict, predicate_dict)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 393, in parse_effect\n    effects.append(parse_effect(context, eff, type_dict, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 434, in parse_effect\n    return pddl.SimpleEffect(parse_literal(context, alist, {}, predicate_dict))\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 305, in parse_literal\n    return pddl.Atom(pred_id, alist[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 16:27:49,952 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 16:27:49,953 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "on",
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 16:27:49,967 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 16:27:49,975 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 16:29:23,118 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:29:23,166 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb/llm_suggestion.pddl
2025-06-29 16:29:23,189 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 16:29:23,194 [INFO] 127.0.0.1 - - [29/Jun/2025 16:29:23] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 16:29:23,224 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-162433-9870fb'} form_keys=[]
2025-06-29 16:29:23,269 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 16:29:23,299 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 16:29:23,299 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "on",
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 16:29:23,306 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 16:29:23,308 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 16:30:31,686 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 16:30:31,718 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-162433-9870fb
2025-06-29 16:30:31,723 [INFO] ✅ Riflessione completata.
2025-06-29 16:30:31,743 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 16:30:31,745 [INFO] 127.0.0.1 - - [29/Jun/2025 16:30:31] "GET /result?session=the_hero_must_reach_the_tower_-20250629-162433-9870fb HTTP/1.1" 200 -
2025-06-29 16:30:31,818 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 16:30:31,823 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 16:30:31,836 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 16:30:31,837 [INFO] 127.0.0.1 - - [29/Jun/2025 16:30:31] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 16:30:31,838 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 16:30:31,838 [INFO] 127.0.0.1 - - [29/Jun/2025 16:30:31] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:14:20,468 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-06-29 17:14:20,469 [INFO] [33mPress CTRL+C to quit[0m
2025-06-29 17:14:29,673 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:14:29,728 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:14:29,731 [INFO] 127.0.0.1 - - [29/Jun/2025 17:14:29] "GET / HTTP/1.1" 200 -
2025-06-29 17:14:29,769 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:14:29,770 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:14:29,790 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:14:29,791 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:14:29,792 [INFO] 127.0.0.1 - - [29/Jun/2025 17:14:29] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:14:29,792 [INFO] 127.0.0.1 - - [29/Jun/2025 17:14:29] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:14:32,893 [DEBUG] → REQUEST POST /generate args={} form_keys=['run', 'lore_path']
2025-06-29 17:14:33,359 [INFO] 📤 Invio prompt a Ollama con modello: mistral e num_ctx: 2048
2025-06-29 17:14:33,364 [DEBUG] Starting new HTTP connection (1): 127.0.0.1:11434
2025-06-29 17:19:26,322 [DEBUG] http://127.0.0.1:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 17:19:27,843 [INFO] ⏱️ Planner terminato in 1.36s (exit code: 30)
2025-06-29 17:19:27,845 [DEBUG] STDOUT:
==> Eseguo Fast Downward su /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/problem.pddl con lazy_greedy([ff()]) (dominio: robot-world)
INFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/bin/python3 /home/paolop/downward/builds/release/bin/translate/translate.py /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/domain.pddl /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57/problem.pddl --sas-file output.sas
Parsing...
translate exit code: 30

Driver aborting after translate
INFO     Planner time: 0.36s

2025-06-29 17:19:27,860 [DEBUG] STDERR:
b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 747, in <module>\n    main()\n  File "/home/paolop/downward/builds/release/bin/translate/translate.py", line 705, in main\n    task = pddl_parser.open(\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/pddl_file.py", line 39, in open\n    return parsing_functions.parse_task(domain_pddl, task_pddl)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 634, in parse_task\n    task_name, task_domain_name, task_requirements, objects, init, goal, \\\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 782, in parse_task_pddl\n    yield parse_init(context, init)\n  File "/home/paolop/downward/builds/release/bin/translate/pddl_parser/parsing_functions.py", line 617, in parse_init\n    atom = pddl.Atom(fact[0], fact[1:])\n  File "/home/paolop/downward/builds/release/bin/translate/pddl/conditions.py", line 232, in __init__\n    self.hash = hash((self.__class__, self.predicate, self.args))\nTypeError: unhashable type: \'list\'\n'

2025-06-29 17:19:28,113 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 17:19:28,116 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 17:19:28,144 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 17:19:28,160 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 17:20:45,651 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 17:20:45,696 [ERROR] ❌ Fallita la raffinazione automatica: ❌ DOMAIN non valido. Controlla 'llm_raw_output.txt'
2025-06-29 17:20:45,724 [DEBUG] ← RESPONSE POST /generate status=302
2025-06-29 17:20:45,740 [INFO] 127.0.0.1 - - [29/Jun/2025 17:20:45] "[32mPOST /generate HTTP/1.1[0m" 302 -
2025-06-29 17:20:45,805 [DEBUG] → REQUEST GET /result args={'session': 'the_hero_must_reach_the_tower_-20250629-171432-dc3f57'} form_keys=[]
2025-06-29 17:20:45,872 [INFO] 🤖 Nessun piano trovato. Avvio riflessione automatica con LLM...
2025-06-29 17:20:45,962 [INFO] 🔁 LLM invoked with error: b'Traceback (most recent call last):\n  File "/home/paolop/downward/builds/relea
2025-06-29 17:20:45,963 [INFO] 🧠 Validation summary: {
  "valid_syntax": true,
  "missing_sections": [],
  "undefined_objects_in_goal": [
    "clear"
  ],
  "undefined_actions": [],
  "mismatched_lore_entities": []
}
2025-06-29 17:20:45,976 [INFO] 🤖 Invio richiesta a Ollama...
2025-06-29 17:20:45,981 [DEBUG] Starting new HTTP connection (1): localhost:11434
2025-06-29 17:23:47,560 [DEBUG] http://localhost:11434 "POST /api/generate HTTP/1.1" 200 None
2025-06-29 17:23:47,565 [WARNING] ⚠️ Delimitatori non trovati: === PROBLEM START === / === PROBLEM END ===
2025-06-29 17:23:47,610 [WARNING] ⚠️ Output LLM incompleto o malformato:
I am an assistant that can help you with PDDL files correction based on the error messages provided. However, please note that I can only provide guidance for common issues, and you may need to adjust the corrections based on your specific context. Here's a sample correction for a simple example:

Let's say the original domain file contains:

=== DOMAIN START ===
(define (domain my_domain)
   (:requirements :equality :quantifiers :action-cost)
   (:predicates
      (at ?x - Location)
      (has_
2025-06-29 17:23:47,638 [INFO] ✅ Suggestions saved in /mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/uploads/the_hero_must_reach_the_tower_-20250629-171432-dc3f57
2025-06-29 17:23:47,649 [INFO] ✅ Riflessione completata.
2025-06-29 17:23:47,940 [DEBUG] ← RESPONSE GET /result status=200
2025-06-29 17:23:47,942 [INFO] 127.0.0.1 - - [29/Jun/2025 17:23:47] "GET /result?session=the_hero_must_reach_the_tower_-20250629-171432-dc3f57 HTTP/1.1" 200 -
2025-06-29 17:23:48,099 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:23:48,109 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:23:48,135 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:23:48,136 [INFO] 127.0.0.1 - - [29/Jun/2025 17:23:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:23:48,138 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:23:48,139 [INFO] 127.0.0.1 - - [29/Jun/2025 17:23:48] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:35:36,522 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:35:36,530 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:35:36,533 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:36] "GET / HTTP/1.1" 200 -
2025-06-29 17:35:36,586 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:35:36,589 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:35:36,626 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:35:36,628 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:36] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:35:36,630 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:35:36,631 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:36] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:35:38,102 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:35:38,105 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:35:38,107 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:38] "GET / HTTP/1.1" 200 -
2025-06-29 17:35:38,151 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:35:38,153 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:35:38,213 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:35:38,220 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:38] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:35:38,245 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:35:38,254 [INFO] 127.0.0.1 - - [29/Jun/2025 17:35:38] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:39:29,508 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:39:29,512 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:39:29,516 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:29] "GET / HTTP/1.1" 200 -
2025-06-29 17:39:29,564 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:39:29,567 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:39:29,584 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:39:29,586 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:29] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:39:29,591 [DEBUG] ← RESPONSE GET /static/js/index.js status=200
2025-06-29 17:39:29,600 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:29] "GET /static/js/index.js HTTP/1.1" 200 -
2025-06-29 17:39:31,038 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:39:31,041 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:39:31,042 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:31] "GET / HTTP/1.1" 200 -
2025-06-29 17:39:31,088 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:39:31,090 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:39:31,106 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:39:31,107 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:31] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:39:31,113 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:39:31,114 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:31] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
2025-06-29 17:39:32,187 [DEBUG] → REQUEST GET / args={} form_keys=[]
2025-06-29 17:39:32,189 [DEBUG] ← RESPONSE GET / status=200
2025-06-29 17:39:32,190 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:32] "GET / HTTP/1.1" 200 -
2025-06-29 17:39:32,236 [DEBUG] → REQUEST GET /static/style.css args={} form_keys=[]
2025-06-29 17:39:32,239 [DEBUG] → REQUEST GET /static/js/index.js args={} form_keys=[]
2025-06-29 17:39:32,257 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-06-29 17:39:32,258 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2025-06-29 17:39:32,263 [DEBUG] ← RESPONSE GET /static/js/index.js status=304
2025-06-29 17:39:32,265 [INFO] 127.0.0.1 - - [29/Jun/2025 17:39:32] "[36mGET /static/js/index.js HTTP/1.1[0m" 304 -
[2025-07-04 11:33:37,199] INFO: 📤 Invio prompt a Ollama con modello: mistral
2025-07-04 18:27:32,761 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:27:32,766 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 149, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1087, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1016, in get_template
    return self._load_template(name, globals)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 65, in get_source
    return self._get_source_fast(environment, template)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 99, in _get_source_fast
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: index.html
2025-07-04 18:27:32,813 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:27:32,814 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:31:04,825 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:31:04,871 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 1, in top-level template code
    {% extends "base.html" %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/base.html", line 15, in top-level template code
    {% block content %}{% endblock %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 24, in block 'content'
    {{ csrf_token() }}
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/utils.py", line 92, in from_obj
    if hasattr(obj, "jinja_pass_arg"):
jinja2.exceptions.UndefinedError: 'csrf_token' is undefined
2025-07-04 18:31:04,955 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:31:04,955 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:34:51,374 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:34:51,429 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 1, in top-level template code
    {% extends "base.html" %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/base.html", line 15, in top-level template code
    {% block content %}{% endblock %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 24, in block 'content'
    {{ csrf_token() }}
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/utils.py", line 92, in from_obj
    if hasattr(obj, "jinja_pass_arg"):
jinja2.exceptions.UndefinedError: 'csrf_token' is undefined
2025-07-04 18:34:51,512 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:34:51,513 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:37:53,485 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:37:53,540 [ERROR] Exception on / [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/core.py", line 14, in index
    return render_template("index.html")
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 1, in top-level template code
    {% extends "base.html" %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/base.html", line 15, in top-level template code
    {% block content %}{% endblock %}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/templates/index.html", line 24, in block 'content'
    {{ csrf_token() }}
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/app_factory.py", line 57, in <lambda>
    self.app.context_processor(lambda: {"csrf_token": lambda: csrf.generate_csrf()})
AttributeError: 'CSRFProtect' object has no attribute 'generate_csrf'
2025-07-04 18:37:53,640 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-04 18:37:53,641 [DEBUG] ← RESPONSE GET / status=500
2025-07-04 18:39:58,454 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:39:58,490 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:39:58,540 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:39:58,554 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:39:58,556 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:39:58,558 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:39:58,560 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:39:58,562 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:39:58,563 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:39:58,594 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:39:58,596 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:39:58,596 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:39:58,598 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 18:39:58,598 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 18:39:58,772 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:39:58,789 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 18:44:05,020 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:44:05,055 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:44:05,107 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:44:05,111 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:44:05,115 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:44:05,117 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:44:05,119 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:44:05,121 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:44:05,129 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:44:05,130 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:44:05,134 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:44:05,135 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 18:44:05,140 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:44:05,147 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 18:44:05,152 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:44:05,180 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 18:44:10,371 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:44:10,383 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:44:10,399 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:44:10,400 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:44:10,568 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:10,570 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:10,574 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:10,574 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:12,621 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:44:12,622 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:44:12,668 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:44:12,669 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:44:12,672 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:44:12,674 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:44:12,676 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:44:12,680 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:44:12,682 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:44:12,684 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:44:12,688 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:44:12,690 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 18:44:12,693 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 18:44:12,694 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:44:12,698 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:44:12,715 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 18:44:12,818 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:44:12,834 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:12,836 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:44:12,839 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:12,840 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:44:12,854 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 18:44:31,953 [DEBUG] → REQUEST POST /api/chatbot/message args={} form=[]
2025-07-04 18:44:31,954 [DEBUG] ← RESPONSE POST /api/chatbot/message status=404
2025-07-04 18:45:44,077 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 18:45:44,091 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 18:45:44,340 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-04 18:45:44,342 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-04 18:47:08,033 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:47:08,035 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:47:08,085 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:47:08,087 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:47:08,089 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:47:08,091 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:47:08,093 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:47:08,094 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:47:08,096 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:47:08,099 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:47:08,102 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 18:47:08,103 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 18:47:08,105 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:47:08,107 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:47:08,119 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:47:08,127 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 18:47:08,241 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:47:08,263 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:08,272 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:08,273 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:08,281 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:08,289 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 18:47:11,781 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:47:11,805 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:47:11,817 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:47:11,818 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:47:11,867 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:11,869 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:11,881 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:11,881 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:13,118 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:47:13,120 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:47:13,158 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:47:13,161 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:47:13,163 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:47:13,166 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 18:47:13,168 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:47:13,170 [DEBUG] → REQUEST GET /static/js/index.js args={} form=[]
2025-07-04 18:47:13,171 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 18:47:13,173 [DEBUG] ← RESPONSE GET /static/js/index.js status=404
2025-07-04 18:47:13,176 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 18:47:13,176 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 18:47:13,179 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:47:13,182 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 18:47:13,196 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:47:13,198 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 18:47:13,220 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:47:13,245 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:13,247 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 18:47:13,253 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:13,254 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 18:47:13,282 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 18:48:45,660 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 18:48:45,667 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 18:55:38,656 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 18:55:38,687 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 18:55:38,741 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 18:55:38,743 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 18:55:38,745 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 18:55:38,747 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 18:55:38,748 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 18:55:38,773 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 18:55:38,777 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 18:55:38,778 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 18:55:38,778 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 18:55:38,785 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 18:55:38,801 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 18:55:38,825 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:01:47,990 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:01:48,025 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:01:48,096 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:01:48,097 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:01:48,100 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:01:48,102 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:01:48,104 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:01:48,132 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:01:48,135 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:01:48,136 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:01:48,136 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:01:48,140 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:01:48,176 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:01:48,207 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:04:50,318 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:04:50,353 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:04:50,391 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:04:50,392 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:04:50,395 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:04:50,396 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:04:50,397 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:04:50,415 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:04:50,418 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:04:50,419 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:04:50,419 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 19:04:50,431 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:04:50,435 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:04:50,461 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:04:54,980 [DEBUG] → REQUEST GET / args={'lore_path': ''} form=[]
2025-07-04 19:04:54,983 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:04:55,038 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:04:55,041 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:04:55,046 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:04:55,049 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:04:55,050 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:04:55,055 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:04:55,058 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:04:55,059 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 19:04:55,063 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:04:55,077 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:05:40,102 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:05:40,113 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:05:40,127 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:05:40,128 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:05:40,195 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:40,196 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:40,203 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:40,204 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:41,402 [DEBUG] → REQUEST GET / args={'lore_path': ''} form=[]
2025-07-04 19:05:41,406 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:05:41,431 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:05:41,432 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:05:41,441 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:05:41,443 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:05:41,445 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:05:41,447 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:05:41,448 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:05:41,456 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 19:05:41,456 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 19:05:41,457 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:05:41,459 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:05:41,476 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 19:05:41,604 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:05:41,617 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:41,621 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:05:41,634 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:41,635 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:05:41,661 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 19:08:30,060 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:08:30,111 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:08:30,184 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:08:30,187 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:08:30,191 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:08:30,193 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:08:30,224 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:08:30,225 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-04 19:08:30,226 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:08:30,247 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:08:30,438 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:08:30,494 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:08:30,627 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:08:30,646 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:08:31,368 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:08:31,381 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:08:31,383 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:08:31,384 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:08:31,513 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:31,514 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:31,521 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:31,522 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:33,129 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:08:33,132 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:08:33,174 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:08:33,175 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:08:33,187 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:08:33,189 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:08:33,191 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:08:33,192 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:08:33,197 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 19:08:33,199 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:08:33,200 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 19:08:33,223 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 19:08:33,340 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:08:33,351 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:08:33,355 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:33,357 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:08:33,362 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:33,365 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:08:33,367 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:08:33,386 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 19:14:23,132 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:14:23,165 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:14:23,217 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:14:23,222 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:14:23,224 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:14:23,226 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:14:23,243 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-04 19:14:23,244 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:14:23,244 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:14:23,256 [DEBUG] ← RESPONSE GET /static/js/utils.js status=304
2025-07-04 19:14:23,294 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:14:23,323 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=304
2025-07-04 19:14:23,469 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:14:23,485 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:14:23,584 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 19:14:23,591 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 19:14:25,397 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:14:25,407 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-04 19:14:25,414 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:14:25,415 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:14:25,536 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:25,541 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:25,546 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:25,548 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:27,189 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-04 19:14:27,191 [DEBUG] ← RESPONSE GET / status=200
2025-07-04 19:14:27,262 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-04 19:14:27,265 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-04 19:14:27,267 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-04 19:14:27,269 [DEBUG] → REQUEST GET /static/js/utils.js args={} form=[]
2025-07-04 19:14:27,272 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-04 19:14:27,275 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-04 19:14:27,291 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-04 19:14:27,294 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-04 19:14:27,295 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-04 19:14:27,330 [DEBUG] ← RESPONSE GET /static/js/utils.js status=200
2025-07-04 19:14:27,379 [DEBUG] → REQUEST GET /static/img/parchment_texture.png args={} form=[]
2025-07-04 19:14:27,395 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:27,397 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]
2025-07-04 19:14:27,399 [DEBUG] → REQUEST GET /static/style.css.map args={} form=[]
2025-07-04 19:14:27,404 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:27,406 [DEBUG] ← RESPONSE GET /static/style.css.map status=200
2025-07-04 19:14:27,407 [DEBUG] → REQUEST GET /api/lore_files args={} form=[]
2025-07-04 19:14:27,414 [DEBUG] ← RESPONSE GET /static/sounds/success-chime.mp3 status=206
2025-07-04 19:14:27,426 [DEBUG] ← RESPONSE GET /api/lore_files status=200
2025-07-04 19:14:27,427 [DEBUG] ← RESPONSE GET /static/img/parchment_texture.png status=200
2025-07-04 19:14:31,307 [DEBUG] → REQUEST POST /api/pipeline/run args={} form=[]
[2025-07-04 19:14:31,692] INFO: 📤 Invio prompt a Ollama con modello: mistral
2025-07-04 19:18:00,148 [DEBUG] ← RESPONSE POST /api/pipeline/run status=200
2025-07-04 19:18:00,219 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-04 19:18:00,222 [DEBUG] → REQUEST GET /static/sounds/success-chime.mp3 args={} form=[]

[2025-07-07 14:15:51,601] INFO: 📤 Invio prompt a Ollama con modello: mistral
[2025-07-07 14:28:58,624] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 15:06:41,927] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 15:47:11,900] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 15:55:59,004] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 16:03:52,732] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 16:22:38,463] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 16:34:54,772] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 17:01:49,877] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-07 17:09:12,315] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 09:52:36,616] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 10:48:26,015 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 10:48:26,016 [DEBUG] ← RESPONSE GET / status=404
2025-07-08 10:48:26,192 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-08 10:48:26,193 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-08 10:51:43,682 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 10:51:43,683 [DEBUG] ← RESPONSE GET / status=404
2025-07-08 10:52:40,250 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 10:52:40,279 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 10:52:40,317 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 10:52:40,319 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 10:52:40,336 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 10:52:40,337 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
[2025-07-08 11:01:45,653] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 11:05:49,617] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 11:08:29,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-08 11:15:21,089] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 11:18:47,405 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 11:18:47,436 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 11:18:47,480 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 11:18:47,485 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 11:18:47,507 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 11:18:47,509 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 11:19:42,915 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 11:19:42,983 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 11:19:43,084 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 11:19:43,089 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 11:19:43,142 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 11:19:43,144 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 11:19:52,740 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 11:19:53,752 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 16:25:54,122 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:25:54,139 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:25:54,565 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:25:54,741 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:25:56,195 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-08 16:25:56,198 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-08 16:40:43,025 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:40:43,044 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:40:43,061 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:40:43,062 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:40:43,073 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:40:43,074 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:42:02,699 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:02,703 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:02,718 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:02,719 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:02,721 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:02,723 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:42:04,620 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:04,625 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:04,643 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:04,644 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:04,649 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:04,651 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:42:25,221 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:25,244 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:25,258 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:25,259 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:25,271 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:25,272 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:42:34,664 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:34,675 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:42:34,676 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:42:34,677 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:42:37,545 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:42:37,557 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:42:37,573 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:42:37,574 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:42:37,574 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:42:37,575 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:42:37,581 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:42:37,587 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:44:48,119 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:44:48,142 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:44:48,162 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:44:48,164 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:44:48,175 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:44:48,175 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 16:44:51,318 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:44:51,332 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:44:51,333 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:44:51,347 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:44:52,650 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:44:52,653 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:44:52,675 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:44:52,676 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:44:52,677 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:44:52,678 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:44:52,684 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:44:52,686 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:46:59,140 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:46:59,162 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:46:59,180 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:46:59,181 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:46:59,191 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:46:59,191 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:47:02,427 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:47:02,444 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:47:02,445 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:47:02,450 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:47:03,877 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:47:03,886 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:47:03,904 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:47:03,905 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:47:03,906 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:47:03,911 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:47:03,917 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:47:03,919 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:48:19,573 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:48:19,595 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:48:19,612 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:48:19,613 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:48:19,623 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:48:19,623 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:48:21,788 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:48:21,809 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:48:21,810 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:48:21,813 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 16:48:23,420 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 16:48:23,423 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 16:48:23,451 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 16:48:23,452 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 16:48:23,453 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 16:48:23,454 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 16:48:23,457 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 16:48:23,457 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=200
2025-07-08 16:48:26,576 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 16:48:26,723 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:08:08,883 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:08:08,907 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:08:08,923 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:08:08,925 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:08:08,936 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:08:08,936 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=304
2025-07-08 17:08:15,850 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:08:16,051 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:18:22,482 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:18:22,504 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:18:22,521 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:18:22,522 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:18:22,523 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:18:22,528 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:18:26,501 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:18:26,502 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:18:32,452 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:18:32,458 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:18:32,460 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:18:32,461 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:18:38,565 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:18:38,569 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:18:38,590 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:18:38,590 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:18:38,593 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:18:38,594 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:18:38,595 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:18:38,596 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 17:19:30,835 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:19:30,860 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:19:30,879 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:19:30,881 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:19:30,884 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:19:30,892 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:19:35,669 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:35,671 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:40,067 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:40,067 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:41,398 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:41,399 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:41,420 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:41,420 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:42,966 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:19:42,972 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:19:42,987 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:42,988 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:42,994 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:19:42,994 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:19:42,996 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:19:43,000 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 17:19:45,095 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:45,096 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:45,118 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:45,119 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:19:52,457 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:19:52,458 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:19:52,475 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:19:52,476 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:23:31,544 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:23:31,571 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:23:31,587 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:23:31,588 [DEBUG] → REQUEST GET /static/js/chatbot.js args={} form=[]
2025-07-08 17:23:31,590 [DEBUG] ← RESPONSE GET /static/js/chatbot.js status=404
2025-07-08 17:23:31,596 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:23:34,830 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:23:34,831 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:23:38,021 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:23:38,026 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:23:38,036 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:23:38,042 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:23:40,109 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:23:40,110 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:23:40,132 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:23:40,133 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:34:29,355 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:34:29,383 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:34:29,409 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:34:29,410 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:34:29,420 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:34:29,420 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 17:34:40,580 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:34:40,626 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:35:59,838 [DEBUG] → REQUEST POST / args={} form=['message']
2025-07-08 17:35:59,839 [DEBUG] ← RESPONSE POST / status=405
2025-07-08 17:35:59,870 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 17:35:59,870 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 17:36:04,482 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:36:04,513 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:36:04,526 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:36:04,526 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:36:04,547 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:36:04,551 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:36:12,031 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:36:12,034 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:36:12,049 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:36:12,050 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:36:12,053 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:36:12,056 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:36:13,095 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:36:13,099 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:36:13,114 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:36:13,115 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:36:13,120 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:36:13,122 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:36:18,744 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:36:18,781 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:36:20,263 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:36:20,294 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:40:22,621 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:40:22,643 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:40:22,658 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:40:22,660 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:40:22,667 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:40:22,669 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:40:26,342 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:40:26,431 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:40:28,115 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:40:28,142 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:43:05,746 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:43:05,767 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:43:05,784 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:43:05,785 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:43:05,796 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:43:05,796 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:43:10,276 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:43:10,388 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:51:44,360 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:51:44,384 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:51:44,400 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:51:44,401 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:51:44,408 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:51:44,409 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:51:47,893 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:51:47,917 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:53:25,635 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:53:25,654 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:53:25,669 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:53:25,671 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:53:25,677 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:53:25,679 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:53:29,988 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:53:30,012 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:55:30,769 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:55:30,791 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:55:30,806 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:55:30,807 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:55:30,815 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:55:30,815 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:55:34,177 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:55:34,189 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:57:39,727 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:57:39,751 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:57:39,775 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:57:39,776 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:57:39,784 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:57:39,786 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:57:46,387 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:57:46,462 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 17:58:46,328 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 17:58:46,360 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 17:58:46,376 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 17:58:46,378 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 17:58:46,392 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 17:58:46,392 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 17:58:50,389 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-08 17:58:50,415 [DEBUG] ← RESPONSE POST /message status=500
2025-07-08 18:00:31,644 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:00:31,666 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:00:31,689 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:00:31,690 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:00:31,700 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:00:31,701 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:00:37,214 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:00:37,328] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:08:21,030 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:08:21,052 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:08:21,070 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:08:21,071 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:08:21,080 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 18:08:21,083 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:08:26,927 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:08:27,071] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:08:35,154 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:08:35,162 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:08:35,170 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:08:35,173 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:13:07,213 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:13:07,236 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:13:07,254 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:13:07,255 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:13:07,266 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:13:07,267 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:13:15,697 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:13:15,826] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:13:27,413 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:13:27,421 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:13:27,435 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:13:27,437 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:21:47,092 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:21:47,118 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:21:47,133 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:21:47,133 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:21:47,145 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:21:47,145 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:21:51,402 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:21:51,512] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:31:01,018 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:31:01,043 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:31:01,075 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:31:01,075 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:31:01,085 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:31:01,086 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:31:07,421 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-08 18:31:07,553] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:36:41,531 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:36:41,554 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:36:41,569 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:36:41,569 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:36:41,582 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:36:41,583 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:36:46,066 [DEBUG] → REQUEST GET / args={'message': ''} form=[]
2025-07-08 18:36:46,079 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:36:46,103 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:36:46,104 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:36:46,108 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:36:46,110 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:36:50,873 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:36:50,878 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:36:50,934 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:36:50,941 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:37:04,824 [DEBUG] → REQUEST GET / args={'message': ''} form=[]
2025-07-08 18:37:04,829 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:37:04,851 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:37:04,852 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:37:04,855 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:37:04,855 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:37:04,864 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 18:37:04,867 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:37:09,697 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:37:09,753 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:37:09,951] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:39:06,521 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:39:06,544 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:39:06,560 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:39:06,563 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:39:06,571 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:39:06,572 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:39:12,903 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:39:12,952 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:39:13,057] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:40:02,169 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:40:02,190 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:40:02,207 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:40:02,208 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:40:02,214 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 18:40:02,215 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:40:07,437 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:40:07,474 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:40:07,588] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:40:10,425 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:40:10,434 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:40:10,445 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:40:10,447 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:43:14,669 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:43:14,703 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:43:14,765 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:43:14,768 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:43:14,787 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:43:14,788 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:43:19,583 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:43:19,661 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:43:19,782] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:48:01,909 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:48:01,941 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:48:01,967 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:48:01,970 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:48:01,989 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:48:01,990 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 18:48:07,347 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:48:07,461 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-08 18:50:27,692 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:50:27,734 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:50:27,787 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:50:27,790 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:50:27,807 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:50:27,810 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:50:30,767 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:50:30,771 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:50:30,797 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:50:30,804 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:50:30,809 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:50:30,818 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:50:36,859 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:50:36,954 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:50:37,207] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:52:38,750 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:52:38,796 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:52:39,013 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:52:39,015 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 18:57:43,736 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 18:57:43,780 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 18:57:43,829 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:57:43,835 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 18:57:43,853 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:57:43,855 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 18:57:49,661 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 18:57:49,777 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 18:57:50,927] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 18:58:33,644 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 18:58:33,666 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 18:58:33,679 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 18:58:33,683 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 19:01:23,863 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 19:01:23,906 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 19:01:23,982 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 19:01:23,995 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 19:01:24,000 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 19:01:24,011 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 19:01:29,496 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 19:01:29,592 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 19:01:29,990] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 19:08:07,321 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 19:08:07,351 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 19:08:07,398 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 19:08:07,411 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 19:08:07,432 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 19:08:07,447 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 19:08:13,333 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 19:08:13,437 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 19:08:13,771] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:06:03,350 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:06:03,355 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:06:03,357 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:06:03,374 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:06:04,388 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:06:04,397 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:06:04,444 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:06:04,445 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:06:04,465 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:06:04,480 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 21:06:04,505 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:06:04,525 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:06:08,620 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:06:08,715 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:06:08,824] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:08:10,869 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:08:10,897 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:08:10,927 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:08:10,940 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:08:10,954 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:08:10,962 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:08:15,367 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:08:15,377 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:08:15,386 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:08:15,387 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:08:21,480 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:08:21,590 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:08:21,983] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:12:37,260 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:12:37,299 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:12:37,341 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:12:37,358 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:12:37,360 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:12:37,372 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:12:44,599 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:12:44,715 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:12:45,139] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:13:41,960 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:13:41,981 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:13:42,020 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:13:42,022 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:15:22,361 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:15:22,400 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:15:22,452 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:15:22,469 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:15:22,485 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:15:22,496 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 21:17:14,998 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:17:15,117 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:17:15,496] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:17:15,915 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:17:15,941 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:17:15,945 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:17:15,946 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:33:14,353 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:33:14,393 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:33:14,456 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:33:14,467 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 21:33:14,473 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:33:14,483 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:33:21,115 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:33:21,123 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:33:21,137 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:33:21,138 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:33:24,251 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:33:24,368 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:33:24,887] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:35:38,707 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:35:38,751 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:35:38,805 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:35:38,818 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:35:38,819 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:35:38,826 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 21:35:45,642 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:35:45,651 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:35:45,656 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 21:35:45,658 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 21:35:47,040 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:35:47,163 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:35:47,652] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-08 21:48:57,003 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:48:57,036 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:48:57,103 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:48:57,118 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:48:57,151 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:48:57,160 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 21:49:06,912 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:49:06,976 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:49:07,325] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 21:56:52,333 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 21:56:52,404 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 21:56:52,480 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 21:56:52,509 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 21:56:52,580 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 21:56:52,599 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 21:56:56,522 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 21:56:56,615 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 21:56:57,061] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:04:17,344 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:04:17,354 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:04:17,356 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:04:17,358 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:09:53,219 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:09:53,245 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:09:53,272 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:09:53,282 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:09:53,722 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:09:53,736 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:10:06,024 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:10:06,057 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:10:06,223] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:14:04,697 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:14:04,732 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:14:04,776 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:14:04,792 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:14:04,793 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:14:04,802 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:14:10,846 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:14:10,896 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:14:11,086] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:24:57,019 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:24:57,210 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:24:57,249 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:24:57,320 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:24:57,324 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:24:57,346 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:25:02,737 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:25:02,786 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:25:03,049] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:25:34,291 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:25:34,295 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:25:34,296 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:25:34,322 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:25:36,575 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:25:36,583 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:25:36,596 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:25:36,597 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:36:39,677 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:36:39,681 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:36:39,708 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:36:39,710 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:36:39,711 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:36:39,716 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 22:36:40,304 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:36:40,315 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 22:36:43,973 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:36:44,018 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:36:44,128] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 22:52:22,407 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 22:52:22,430 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 22:52:22,445 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:52:22,458 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:52:22,517 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 22:52:22,521 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 22:52:25,952 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 22:52:25,961 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 22:52:25,962 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 22:52:25,966 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 22:52:27,257 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 22:52:27,302 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 22:52:27,444] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:03:36,998 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:03:37,027 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:03:37,044 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:03:37,055 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:03:37,376 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:03:37,380 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 23:03:43,177 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:03:43,219 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:03:43,330] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:07:55,235 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:07:55,261 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:07:55,279 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:07:55,287 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:07:55,425 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:07:55,453 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:08:14,521 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:08:14,552 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:08:14,570 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:08:14,578 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:08:14,975 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:08:14,988 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:08:20,545 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:08:20,618 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:08:20,895] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:08:22,405 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:08:22,411 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:08:22,438 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:08:22,439 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:08:30,255 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:08:30,259 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:08:30,300 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:08:30,306 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-08 23:08:30,314 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:08:30,315 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:08:30,446 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:08:30,458 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-08 23:08:35,661 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:08:35,709 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:08:35,746] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:18:49,644 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:18:49,669 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:18:49,689 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:18:49,702 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:18:50,072 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:18:50,109 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:18:58,123 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:18:58,160 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:18:58,315] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:33:55,369 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:33:55,394 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:33:55,409 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:33:55,418 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:33:55,805 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:33:55,815 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:33:59,192 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:33:59,224 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:33:59,318] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:38:50,698 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:38:50,706 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:38:50,825 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:38:50,826 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:39:05,586 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:39:05,587 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-08 23:46:30,564 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:46:30,583 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:46:30,601 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:46:30,608 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:46:30,815 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:46:30,851 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:46:36,239 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:46:36,267 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:46:36,358] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:54:22,395 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:54:22,418 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:54:22,464 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:54:22,474 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:54:22,565 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:54:22,576 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:54:24,835 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:54:24,839 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:54:24,869 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:54:24,878 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:54:24,881 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:54:24,905 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:54:26,421 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-08 23:54:26,425 [DEBUG] ← RESPONSE GET / status=200
2025-07-08 23:54:26,440 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:54:26,444 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:54:26,446 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-08 23:54:26,451 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-08 23:54:30,095 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-08 23:54:30,131 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-08 23:54:30,234] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-08 23:59:43,127 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-08 23:59:43,136 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-08 23:59:43,263 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-08 23:59:43,264 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:09:12,115 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:09:12,138 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:09:12,161 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:09:12,172 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:09:12,542 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:09:12,565 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:09:36,265 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:09:36,293 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:09:36,378] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 00:09:40,163 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:09:40,170 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 00:09:40,171 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:09:40,171 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:15:04,522 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:15:04,588 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:15:04,678 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:15:04,708 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:15:04,764 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:15:04,784 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-09 00:15:07,932 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:15:08,031 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:15:08,451] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 00:15:14,101 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:15:14,108 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:15:14,125 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 00:15:14,126 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:27:22,007 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:27:22,043 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:27:22,088 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:27:22,101 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:27:22,157 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:27:22,173 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:27:26,590 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:27:26,703 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:27:27,395] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 00:27:31,538 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:27:31,544 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:27:31,573 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 00:27:31,574 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 00:37:32,776 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:37:32,819 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:37:32,888 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:37:32,901 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:37:32,965 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:37:32,979 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:37:35,524 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 00:37:35,529 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 00:37:35,553 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 00:37:35,560 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 00:37:35,565 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 00:37:35,574 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 00:37:39,680 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 00:37:39,769 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 00:37:40,139] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:09:26,221 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:09:26,248 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:09:26,272 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:09:26,281 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:09:26,349 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:09:26,356 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:09:34,750 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:09:34,811 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:09:35,006] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:20:25,100 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:20:25,141 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:20:25,192 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:20:25,207 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:20:25,283 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:20:25,304 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:20:30,030 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:20:30,153 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-09 10:24:24,092 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:24:24,133 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:24:24,193 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:24:24,207 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:24:24,294 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:24:24,312 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:24:30,922 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:24:30,931 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:24:30,940 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-09 10:24:30,941 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-09 10:24:32,180 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:24:32,271 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:24:32,728] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:29:13,425 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:29:13,511 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:29:13,732] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-09 10:35:21,244] ERROR: ❌ Errore di rete con Ollama: HTTPConnectionPool(host='127.0.0.1', port=11434): Read timed out. (read timeout=360)
2025-07-09 10:36:40,660 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:36:40,688 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:36:40,735 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:36:40,748 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:36:40,853 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:36:40,871 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:36:47,089 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:36:47,153 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:36:47,356] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 10:48:21,349 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:48:21,377 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:48:21,420 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:48:21,430 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:48:21,488 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:48:21,501 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:48:27,191 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:48:27,214 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 126, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 412, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 381, in build_pipeline
    builder.add_conditional_edges("ChatFeedback", path=should_continue_after_refine)
NameError: name 'should_continue_after_refine' is not defined
2025-07-09 10:48:27,242 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-09 10:48:27,242 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-09 10:50:07,566 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 10:50:07,597 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 10:50:07,619 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 10:50:07,631 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 10:50:07,878 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 10:50:07,946 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 10:50:12,825 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 10:50:12,889 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 10:50:13,072] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 11:03:18,410 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-09 11:03:18,437 [DEBUG] ← RESPONSE GET / status=200
2025-07-09 11:03:18,468 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-09 11:03:18,480 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-09 11:03:18,550 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-09 11:03:18,558 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-09 11:03:22,534 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-09 11:03:22,568 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-09 11:03:22,771] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 11:12:39,733 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-09 11:12:39,988] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-09 11:14:11,612 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 10:55:59,052 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 10:55:59,082 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 10:55:59,100 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 10:55:59,109 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 10:55:59,113 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 10:55:59,120 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 10:56:02,821 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 10:56:02,857 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 10:59:56,168 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 10:59:56,226 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 10:59:56,247 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 10:59:56,264 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 10:59:56,625 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 10:59:56,660 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:00:02,341 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:00:01,533 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 11:04:11,655 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:04:11,698 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:04:11,731 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:04:11,741 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:04:11,743 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:04:11,748 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:04:21,237 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:04:21,304 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 11:12:18,330 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:12:18,364 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:12:18,404 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:12:18,418 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:12:18,429 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:12:18,460 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:12:23,669 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:12:23,720 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:12:23,845] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:12:46,890 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:12:46,899 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:12:46,912 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:12:46,913 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:12:48,110 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:12:48,115 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:12:48,152 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:12:48,153 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:12:48,154 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:12:48,161 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 11:12:48,192 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:12:48,204 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:12:52,764 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:12:52,824 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:12:52,864] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:18:55,944 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:18:55,968 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:18:55,989 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:18:56,000 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:18:56,012 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:18:56,020 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:18:59,889 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:18:59,932 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:19:00,074] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:20:15,089 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:20:15,119 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:20:15,142 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:20:15,155 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:20:15,163 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:20:15,172 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:20:19,687 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:20:19,730 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:20:19,866] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:20:29,642 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:20:29,654 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:20:29,663 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:20:29,664 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:20:31,712 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:20:31,718 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:20:31,769 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:20:31,770 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 11:20:31,772 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 11:20:31,778 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 11:20:31,804 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:20:31,814 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:20:32,979 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 11:20:32,983 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 11:20:35,885 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:20:35,947 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:20:35,990] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:25:40,982 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:25:41,012 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:25:41,030 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:25:41,039 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:25:41,055 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:25:41,067 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:25:46,134 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:25:46,181 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:25:46,480] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:28:04,476 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:28:04,502 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:28:04,520 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:28:04,532 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:28:04,983 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:28:05,010 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 11:28:07,754 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:28:07,810 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 11:28:52,725 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:28:52,760 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:28:52,792 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:28:52,803 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:28:53,193 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:28:53,235 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:28:56,763 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:28:56,807 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:28:56,940] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:35:40,210 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:35:40,235 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:35:40,252 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:35:40,265 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:35:40,278 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:35:40,292 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:35:43,751 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:35:43,880 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:35:44,158] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:38:54,173 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:38:54,208 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:38:54,254 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:38:54,269 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:38:54,270 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:38:54,282 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:38:59,598 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:38:59,670 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:38:58,815] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:49:18,011 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:49:18,040 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:49:18,083 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:49:18,100 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:49:18,101 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:49:18,110 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:49:22,531 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:49:22,573 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:49:22,752] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:49:22,908] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 11:50:24,640 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:50:24,666 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:50:24,696 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:50:24,705 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:50:24,715 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:50:24,723 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:50:28,173 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:50:28,216 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:50:28,387] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 11:58:05,081 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 11:58:05,110 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 11:58:05,153 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 11:58:05,167 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 11:58:05,170 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 11:58:05,175 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 11:58:10,810 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:58:10,854 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 11:58:10,974] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:58:11,114] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 11:58:16,775 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 11:58:16,900] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:58:16,944] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
[2025-07-10 11:58:16,968] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 11:58:17,005] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 11:58:17,106 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 11:58:17,636 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 11:58:17,718 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 12:03:00,635 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:03:00,669 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:03:00,715 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:03:00,725 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:03:00,736 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:03:00,744 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:03:10,223 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:03:10,290 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:03:10,397] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:09:22,232] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:29:13,215 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:29:13,243 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:29:13,263 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:29:13,272 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:29:13,662 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:29:13,674 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:29:17,453 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:29:17,495 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:29:17,753] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:29:17,810] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:29:17,844] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:29:17,888] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:31:26,408 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:31:26,429 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:31:26,447 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:31:26,456 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:31:26,896 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:31:26,921 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:31:30,931 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:31:30,970 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:31:31,112] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:31:31,176] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:32:29,249 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:32:29,274 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:32:29,292 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:32:29,302 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:32:29,315 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:32:29,323 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:32:32,834 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:32:32,866 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:32:32,997] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:32:33,046] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 12:33:18,445 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:33:18,471 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:33:18,489 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:33:18,497 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:33:18,500 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:33:18,511 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:33:22,044 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:33:22,084 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:33:22,192] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:33:22,243] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:34:35,837 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:34:35,945] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:35,990] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:34:36,025] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:36,060] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:34:36,113 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 12:34:36,654 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:34:36,689 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:34:36,719] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:36,757] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:34:36,783] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:34:36,821] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:35:11,389 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:35:11,490] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:11,524] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:35:11,547] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:11,581] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:35:11,644 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 12:35:12,177 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:35:12,214 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:35:12,249] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:12,284] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:35:12,308] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:12,344] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:35:39,856 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:35:39,883 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:35:39,900 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:35:39,910 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:35:40,451 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:35:40,465 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:35:45,626 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:35:45,685 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:35:44,713] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:44,764] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:35:44,797] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:35:44,835] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:36:39,872 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:36:39,895 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:36:39,913 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:36:39,921 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:36:40,302 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:36:40,332 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:36:43,773 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:36:43,823 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:36:43,951] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:36:43,998] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
[2025-07-10 12:36:44,035] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:36:44,073] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 12:37:58,159 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:37:58,190 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:37:58,215 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:37:58,228 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:37:58,230 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:37:58,234 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:38:03,992 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:38:04,043 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:38:04,192] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 12:38:04,242] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 12:48:00,307 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:48:00,334 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:48:00,350 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:48:00,359 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:48:00,796 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:48:00,816 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 12:48:14,217 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:48:14,499] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:30,190 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:48:30,247 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:48:30,283] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:30,874 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:48:30,911 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:48:30,943] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:31,119 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:48:31,186 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:48:31,223] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:48:42,875 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:48:42,880 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:48:42,933 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:48:42,937 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:48:42,941 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:48:42,945 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:49:11,790 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 12:49:11,823 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 12:49:11,869 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 12:49:11,883 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 12:49:11,884 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 12:49:11,892 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 12:49:15,960 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 12:49:16,024 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 12:49:16,246] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 12:59:21,435 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 12:59:21,548] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 13:06:20,393] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 13:12:08,330] ERROR: ❌ Errore di rete con Ollama: HTTPConnectionPool(host='127.0.0.1', port=11434): Read timed out. (read timeout=360)
2025-07-10 13:12:09,144 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 13:12:10,162 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 13:12:10,408 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 13:12:12,071] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:12:52,623 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:12:52,695 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:12:52,793 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:12:52,818 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:12:52,822 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 14:12:52,842 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:13:03,680 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:13:04,336] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:13:13,656 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:13:13,813 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:13:13,906] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:03,530 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:20:03,570 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:20:03,616 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:20:03,634 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:20:03,648 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:20:03,660 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:20:10,599 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:11,393] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:11,472] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:11,754 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:11,769 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:11,902 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:11,995] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:12,069] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:16,873 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:17,199] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:17,267] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:17,482 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:17,493 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:17,568 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:17,673] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:17,748] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:27,086 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:27,453] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:27,512] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:27,519 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:27,605 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:27,670] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:27,744] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:27,747 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:27,759 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:27,867 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:27,948] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:28,020] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:33,547 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:20:33,549 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 14:20:33,550 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 14:20:33,560 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:20:34,134 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:34,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:34,585] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:34,786 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:34,800 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:34,902 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:35,042] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:35,118] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:47,246 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:20:47,605] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:47,668] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:47,900 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:20:47,917 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:48,087 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:48,195] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:48,271] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:50,016 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:50,229 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:50,373] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:50,456] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:52,294 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,484 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,491 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:52,576 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:52,646 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,767 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:52,828 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:52,981 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:20:53,017 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:20:53,105 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,173] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:53,191 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:20:53,251] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:53,275 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,335] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:53,382 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:20:53,424] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:53,464 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:20:53,552 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:20:53,608] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:20:53,630 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:20:53,674] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:20:53,745] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:21:01,301 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:21:01,560 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:21:01,693] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:21:01,769] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:21:45,510 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:21:45,551 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:21:45,618 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:21:45,634 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:21:45,668 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:21:45,684 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:21:51,456 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:21:51,590 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:21:52,100] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:21:52,176] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:17,613 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:22:17,950] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:18,027] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:18,317 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:22:18,333 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:22:18,460 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:22:18,589] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:18,662] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:26,045 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:22:26,255 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:22:26,398] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:26,465] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:29,811 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:22:30,117] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:30,180] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
[2025-07-10 14:22:30,248] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:30,315] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:22:30,426 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:22:30,967 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:22:31,135 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:22:31,252] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:31,320] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
[2025-07-10 14:22:31,366] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:22:31,429] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:23:07,480 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:23:07,768] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:23:07,835] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:23:08,096 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:23:08,109 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:23:08,287 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:23:08,478] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:23:08,549] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:23:35,123 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore2.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:23:35,248 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:23:35,442] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:23:35,505] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:04,248 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:25:04,296 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:25:04,353 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:25:04,368 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:25:04,395 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:25:04,410 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:25:08,133 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:08,135 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 14:25:11,831 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:11,982 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:25:12,557] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:12,628] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:21,722 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:25:22,058] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:22,122] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:22,324 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:25:22,334 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:22,413 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:25:22,528] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:22,594] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:25:23,521 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:23,686 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:23,711 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:23,785 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:23,841 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,011 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,016 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,131 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,168 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,290 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,359 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,534 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,547 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,610 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,690 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:24,814 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:25:24,928 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:25:25,104 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:25:25,209] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:25:25,278] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:29:18,505 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:29:18,581 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:29:18,657 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:29:18,677 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:29:18,678 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:29:18,693 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:29:24,821 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:29:25,351] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:29:25,424] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:29:25,667 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:29:25,680 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:29:25,772 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:29:25,872] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:29:25,942] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:30:39,582 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:30:39,624 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:30:39,666 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:30:39,683 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:30:39,696 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:30:39,711 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:30:48,372 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:30:49,227] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:30:49,300] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:30:49,615 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:30:49,638 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:30:49,656 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 146, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
NameError: name 'reset' is not defined
2025-07-10 14:30:49,694 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-10 14:30:49,696 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-10 14:31:11,407 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:31:11,762] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:31:11,826] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:31:12,042 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:31:12,055 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:31:12,067 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 146, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
NameError: name 'reset' is not defined
2025-07-10 14:31:12,075 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-10 14:31:12,076 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-10 14:31:12,818 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:31:12,838 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 146, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
NameError: name 'reset' is not defined
2025-07-10 14:31:12,852 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-10 14:31:12,853 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-10 14:37:53,030 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:37:53,067 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:37:53,134 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:37:53,149 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:37:53,152 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:37:53,166 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:37:58,941 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:37:59,057 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:37:59,423] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:37:59,498] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:03,643 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:38:03,923] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:03,994] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:04,300 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:38:04,316 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:04,447 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:04,578] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:04,650] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:05,745 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:05,939 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:06,079] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:06,150] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:08,184 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:38:08,193 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:38:08,233 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:38:08,235 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:38:08,245 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:38:08,248 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:38:22,819 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:38:23,177] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:23,245] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:23,499 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:38:23,518 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:23,676 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:23,790] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:23,861] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:28,325 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:38:28,632] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:28,693] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:38:28,903 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:38:29,444 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:38:29,635 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:38:29,847] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:38:29,909] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:39:52,345 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:39:52,372 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:39:52,399 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:39:52,414 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:39:52,427 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:39:52,440 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:40:00,389 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:40:01,140] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:40:01,218] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:40:01,539 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:40:01,554 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:40:01,669 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:40:01,810] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:40:01,874] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (13.0 GiB)"}
2025-07-10 14:46:33,075 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:46:33,116 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:46:33,177 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:46:33,191 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:46:33,204 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:46:33,219 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 14:46:37,486 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:46:37,613 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:46:38,002] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:46:38,072] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:46:41,226 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:46:41,571] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:46:41,638] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:46:41,943 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:46:41,960 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:46:42,110 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:46:42,313] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:46:42,386] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:48:29,069 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:48:29,114 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:48:29,170 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:48:29,187 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:48:29,489 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:48:29,509 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:48:34,017 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:48:34,793] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:48:34,889] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:48:35,191 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:48:35,207 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:48:35,338 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:48:35,534] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:48:35,604] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.9 GiB)"}
2025-07-10 14:50:28,316 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:50:28,379 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:50:28,478 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:50:28,504 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:50:28,507 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:50:28,527 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:50:33,993 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:34,108 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:34,304] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:34,379] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:50:37,838 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:50:38,034] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:38,101] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-10 14:50:38,190 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:50:38,204 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:50:38,330 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:38,385] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:38,461] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:39,385 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:39,504 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:39,556 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:39,654 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:39,711] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:50:39,774 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:50:39,776] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:39,889 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:40,016] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:40,090] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:40,497 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:40,670 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:40,700 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:40,774 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:40,838 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:40,922 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:40,989] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 14:50:41,010 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
[2025-07-10 14:50:41,100] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:50:41,162 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,163 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,263 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,334 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,431 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,488 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,604 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,643 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,730 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,794 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:41,900 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:41,920 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,022 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,055 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,244 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,275 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,310 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,363 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,422 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-10 14:50:42,445 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 14:50:42,545 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:50:42,634] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:50:42,701] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:53:19,055 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:53:19,107 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:53:19,181 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:53:19,202 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:53:19,204 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:53:19,219 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:53:28,613 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:53:29,395] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:53:29,462] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:53:29,712 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 14:53:29,728 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 14:53:29,856 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 14:53:30,046] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 14:53:30,114] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.8 GiB)"}
2025-07-10 14:55:48,024 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 14:55:48,090 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 14:55:48,192 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 14:55:48,220 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 14:55:48,226 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 14:55:48,248 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 14:55:56,026 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 14:55:57,126] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:00:03,654 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:00:03,956] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:00:09,033 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:00:09,046 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:00:09,119 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:00:09,123 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:00:09,136 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:00:09,139 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:00:10,957 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 15:00:10,961 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:00:12,295 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 15:00:12,299 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:00:14,294 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 15:00:14,299 [DEBUG] ← RESPONSE POST /message status=400
2025-07-10 15:00:14,314 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 15:00:14,318 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:01:06,344 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:01:06,391 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:01:06,435 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:01:06,449 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:01:06,455 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:01:06,470 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:01:13,212 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:01:14,070] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:02:28,264 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:02:28,286 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 15:02:28,289 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 15:02:28,298 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:02:40,774 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:02:40,790 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:02:40,885 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 15:02:40,889 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 15:02:40,894 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:02:40,924 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 15:02:40,948 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:02:40,978 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 15:02:51,008 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:02:51,184 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:02:51,445] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:06:45,361 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:06:45,494 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:06:45,575] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:08:02,218 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:08:02,257 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:08:02,294 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:08:02,309 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:08:02,315 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:08:02,326 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:08:07,628 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:08:07,775 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:08:08,540] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:30:36,662 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:30:36,823] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:36:33,468 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 15:36:34,787 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:36:34,898 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:36:35,019] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:39:39,200 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:39:39,243 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:39:39,289 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:39:39,306 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:39:39,316 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:39:39,328 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:39:40,915 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:39:40,920 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:39:40,949 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:39:40,958 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:39:40,962 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:39:40,975 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:39:49,010 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:39:49,520] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:40:00,097 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:40:00,300] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:40:00,921 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 15:40:01,088] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:40:03,303 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:40:03,353 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:40:03,397] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-10 15:46:03,495] ERROR: ❌ Errore di rete con Ollama: HTTPConnectionPool(host='127.0.0.1', port=11434): Read timed out. (read timeout=360)
2025-07-10 15:53:27,668 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 15:53:27,680 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 15:53:27,757 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:53:27,836] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 15:57:32,385 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 15:57:32,410 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 15:57:32,428 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 15:57:32,435 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 15:57:32,446 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 15:57:32,454 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 15:57:37,049 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 15:57:37,053 [DEBUG] ← RESPONSE POST /message status=400
2025-07-10 15:57:37,061 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 15:57:37,076 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 15:57:43,447 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 15:57:43,560 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 15:57:43,994] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:01:49,501 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:01:49,533 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:01:49,583 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:01:49,593 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:01:49,640 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:01:49,648 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 16:01:56,036 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:01:56,198 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:01:56,473] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:14:52,203 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 16:14:52,324] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:21:55,323 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 16:21:56,733 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:21:56,783 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:21:56,861] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:29:27,953 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:29:27,983 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:29:28,021 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:29:28,029 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:29:28,036 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:29:28,044 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 16:29:30,593 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:29:30,596 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:29:30,611 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:29:30,617 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:29:30,619 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:29:30,627 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 16:29:34,350 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:29:34,380 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:29:34,563] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:35:51,297 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 16:35:51,395] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:42:52,889 [DEBUG] ← RESPONSE POST /message status=200
2025-07-10 16:42:53,742 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:42:53,824 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:42:53,866] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:49:53,734 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:49:53,762 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:49:53,778 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:49:53,787 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:49:53,803 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:49:53,811 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 16:49:57,402 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 16:49:57,410 [DEBUG] ← RESPONSE POST /message status=400
2025-07-10 16:49:57,418 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1', 'reset': 'true'} form=[]
2025-07-10 16:49:57,420 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:00,826 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:00,829 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:02,178 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:02,181 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:18,976 [DEBUG] → REQUEST GET /stream args={'lore': '— Scegli una lore —', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:18,980 [DEBUG] ← RESPONSE GET /stream status=404
2025-07-10 16:50:46,224 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 16:50:46,500] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:50:48,546 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:50:48,593 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:50:48,635] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 16:53:23,755 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:53:23,762 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 16:53:23,763 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 16:53:23,773 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 16:53:28,338 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 16:53:28,361 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 16:53:28,376 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-10 16:53:28,377 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-10 16:53:28,388 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 16:53:28,397 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-10 16:53:28,427 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 16:53:28,436 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-10 16:53:32,976 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 16:53:33,023 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 16:53:33,191] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 17:13:09,357 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 17:13:09,478 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 17:26:43,813 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 17:26:43,834 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 17:26:43,854 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 17:26:43,862 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 17:26:43,874 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 17:26:43,882 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 17:26:48,888 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 17:26:48,952 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 17:26:49,128] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 17:50:54,646 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 17:50:54,679 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 17:50:54,703 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 17:50:54,715 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 17:50:54,726 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 17:50:54,731 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 17:50:58,361 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 17:50:58,395 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 17:50:58,641] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 17:55:57,805 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 17:55:57,829 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 17:55:57,845 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 17:55:57,854 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 17:55:57,861 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 17:55:57,867 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 17:56:06,000 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 17:56:06,093 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 17:56:06,310] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 18:09:38,197 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 18:09:38,323 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 18:23:45,776 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 18:23:45,804 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 18:23:45,819 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 18:23:45,832 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 18:23:45,842 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 18:23:45,853 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 18:23:49,354 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 18:23:49,395 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 18:23:49,560] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 18:34:06,475 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 18:34:06,573 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 18:35:54,892 [DEBUG] → REQUEST POST /message args={} form=[]
2025-07-10 18:35:55,048 [DEBUG] ← RESPONSE POST /message status=500
2025-07-10 18:36:12,941 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 18:36:12,973 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 18:36:13,022 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 18:36:13,033 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 18:36:13,043 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 18:36:13,055 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 18:36:14,727 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-10 18:36:14,730 [DEBUG] ← RESPONSE GET / status=200
2025-07-10 18:36:14,745 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-10 18:36:14,750 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-10 18:36:14,752 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-10 18:36:14,759 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-10 18:36:18,890 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-10 18:36:18,923 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-10 18:36:19,089] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-10 18:46:56,322 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-10 18:46:56,482] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 09:56:26,401 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 09:56:26,442 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 09:56:26,541 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 09:56:26,557 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 09:56:26,561 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 09:56:26,574 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 10:22:23,308 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 10:22:23,352 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 10:22:23,404 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 10:22:23,423 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 10:22:23,456 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 10:22:23,470 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-11 10:22:25,322 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 10:22:25,327 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 10:22:25,351 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 10:22:25,360 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 10:22:25,363 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 10:22:25,372 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 10:22:32,584 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 10:22:32,740 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 10:22:33,564] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 11:02:56,775 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:02:56,805 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:02:56,822 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:02:56,836 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-11 11:02:56,851 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:02:56,858 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:03:06,740 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:03:06,805 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-11 11:03:12,327 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:03:12,396 [DEBUG] ← RESPONSE GET /stream status=200
2025-07-11 11:03:13,287 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:03:13,319 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:03:23,260] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 11:03:23,362] ERROR: ❌ HTTP Error da Ollama (500): {"error":"model requires more system memory (13.1 GiB) than is available (12.7 GiB)"}
2025-07-11 11:04:39,815 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:04:39,843 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:04:39,869 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:04:39,877 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:04:39,893 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:04:39,900 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:04:41,364 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:04:41,368 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:04:41,384 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:04:41,391 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:04:41,394 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:04:41,402 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:04:44,794 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:04:44,855 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:04:56,544] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 11:12:44,022 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:12:44,049 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:12:44,088 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:12:44,101 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:12:44,102 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:12:44,108 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:12:45,515 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:12:45,518 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:12:45,533 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:12:45,541 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:12:45,542 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:12:45,551 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:12:49,206 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:12:49,252 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:13:01,166] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 11:22:43,700 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:22:43,726 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:22:43,766 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:22:43,779 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:22:43,779 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:22:43,786 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:22:50,728 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:22:50,731 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
TypeError: get_pipeline_with_memory() got an unexpected keyword argument 'reset'
2025-07-11 11:22:50,743 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 11:22:50,744 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 11:23:39,729 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:23:39,778 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:23:39,836 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:23:39,844 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:23:39,849 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:23:39,867 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:23:41,338 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:23:41,341 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:23:41,357 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:23:41,363 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:23:41,364 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:23:41,371 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:23:44,518 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:23:44,553 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:23:57,542] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 11:31:34,997] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 11:37:11,156 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-11 11:37:11,299] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 11:43:58,242] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 11:47:19,221 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:47:19,265 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:47:19,307 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:47:19,324 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:47:19,325 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:47:19,330 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:47:20,574 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 11:47:20,578 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 11:47:20,595 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 11:47:20,601 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 11:47:20,602 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 11:47:20,609 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 11:47:23,829 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 11:47:23,887 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 11:47:24,106] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 14:06:16,591 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 14:06:16,645 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 14:06:16,726 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:06:16,743 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:06:16,748 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 14:06:16,765 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 14:14:21,243 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:14:21,256 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:14:21,267 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 14:14:21,268 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 14:14:23,354 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:14:23,504 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:14:24,613] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 14:37:21,373 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 14:37:21,424 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 14:37:21,480 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:37:21,498 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:37:21,774 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 14:37:21,803 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 14:37:27,914 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:37:27,924 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:37:27,928 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 14:37:27,929 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 14:37:29,179 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:37:29,295 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:37:29,971] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 14:45:00,452 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 14:45:00,500 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 14:45:00,535 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:45:00,553 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:45:00,561 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 14:45:00,572 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 14:45:07,246 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:45:07,256 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:45:07,260 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 14:45:07,261 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 14:45:12,223 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:45:12,366 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:45:12,923] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 14:49:33,692 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 14:49:33,733 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 14:49:33,785 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:49:33,798 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:49:33,848 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 14:49:33,862 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 14:49:38,628 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:49:38,638 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:49:38,647 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 14:49:38,648 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 14:49:59,554 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:49:59,701 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:50:00,528] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 14:56:01,296 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 14:56:01,334 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 14:56:01,381 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:56:01,393 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:56:01,397 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 14:56:01,412 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 14:56:13,423 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 14:56:13,434 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 14:56:13,436 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 14:56:13,437 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 14:56:15,195 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 14:56:15,349 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 14:56:16,160] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:05:18,458 [DEBUG] → REQUEST POST /message args={} form=[]
[2025-07-11 15:05:18,721] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:07:54,296 [DEBUG] → REQUEST GET /message args={} form=[]
2025-07-11 15:07:54,301 [DEBUG] ← RESPONSE GET /message status=405
2025-07-11 15:09:28,807 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:09:28,846 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:09:28,884 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:09:28,900 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:09:28,914 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:09:28,928 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:09:33,757 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:09:33,915 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 15:09:34,846] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:16:01,223 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:16:01,257 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:16:01,289 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:16:01,303 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:16:01,318 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:16:01,327 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:16:05,397 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:16:05,441 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 15:16:05,654] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:19:47,316 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:19:47,329 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 15:19:47,329 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:19:47,331 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 15:23:04,101 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:23:04,125 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:23:04,147 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:23:04,156 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:23:04,171 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:23:04,181 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:23:07,490 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:23:07,500 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 15:23:07,501 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 15:23:07,501 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:23:11,847 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:23:11,927 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 15:23:12,123] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 15:30:00,414] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 15:33:08,430] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:36:08,665 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:36:08,691 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:36:08,709 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:36:08,724 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:36:08,734 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:36:08,744 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:36:12,412 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:36:12,469 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 15:36:12,666] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 15:38:28,498] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:38:45,805 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:38:45,817 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:38:45,826 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 15:38:45,827 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
[2025-07-11 15:42:14,597] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 15:45:27,130] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 15:48:33,393] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 15:50:48,842 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:50:48,869 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:50:48,895 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:50:48,904 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:50:48,922 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:50:48,930 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:50:53,505 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:50:53,506 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 15:50:53,508 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 15:50:53,513 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:50:54,451 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:50:54,516 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 474, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 443, in build_pipeline
    print_pipeline_graph(pipeline)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 481, in print_pipeline_graph
    for node, edges in pipeline.graph.items():
AttributeError: 'CompiledStateGraph' object has no attribute 'graph'
2025-07-11 15:50:54,526 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 15:50:54,527 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 15:54:29,153 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:54:29,172 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:54:29,191 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:54:29,199 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:54:29,605 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:54:29,651 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:54:33,285 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:54:33,305 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 480, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 448, in build_pipeline
    print_pipeline_graph(builder)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 396, in print_pipeline_graph
    for node, edges in builder.graph.items():
AttributeError: 'StateGraph' object has no attribute 'graph'
2025-07-11 15:54:33,318 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 15:54:33,318 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 15:56:13,518 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:56:13,548 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:56:13,575 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:56:13,585 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:56:13,595 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:56:13,603 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:56:18,753 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:56:18,772 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 453, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 421, in build_pipeline
    print_pipeline_graph(builder)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 462, in print_pipeline_graph
    for node, edges in builder.graph.items():
AttributeError: 'StateGraph' object has no attribute 'graph'
2025-07-11 15:56:18,787 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 15:56:18,787 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 15:57:05,315 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:57:05,343 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:57:05,384 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:57:05,394 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:57:05,395 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:57:05,401 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:57:10,171 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:57:10,206 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 456, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 424, in build_pipeline
    print_pipeline_graph(compiled)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 465, in print_pipeline_graph
    for node, edges in builder.graph.items():
AttributeError: 'CompiledStateGraph' object has no attribute 'graph'
2025-07-11 15:57:10,215 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 15:57:10,216 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 15:58:20,229 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:58:20,257 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:58:20,273 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:58:20,283 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:58:20,293 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:58:20,302 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:58:24,541 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:58:24,580 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 456, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 424, in build_pipeline
    print_pipeline_graph(compiled)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 465, in print_pipeline_graph
    for node, edges in graph.graph.items():
AttributeError: 'CompiledStateGraph' object has no attribute 'graph'
2025-07-11 15:58:24,592 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 15:58:24,593 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 15:59:47,148 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 15:59:47,175 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 15:59:47,196 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 15:59:47,206 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 15:59:47,215 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 15:59:47,223 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 15:59:51,672 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 15:59:51,701 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 455, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 421, in build_pipeline
    print_pipeline_graph(builder)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 464, in print_pipeline_graph
    for node, edges in graph.graph.items():
AttributeError: 'StateGraph' object has no attribute 'graph'
2025-07-11 15:59:51,722 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 15:59:51,722 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 16:01:01,240 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 16:01:01,265 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 16:01:01,284 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:01:01,292 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:01:01,604 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 16:01:01,673 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 16:01:05,671 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:01:05,674 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 16:01:05,677 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 16:01:05,688 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:01:06,875 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 16:01:06,886 [ERROR] Exception on /stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/pipeline_chat.py", line 153, in stream_pipeline
    graph = get_pipeline_with_memory(thread_id, reset=reset)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 454, in get_pipeline_with_memory
    pipeline = build_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 421, in build_pipeline
    print_pipeline_graph(builder)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/pddl_pipeline_graph.py", line 462, in print_pipeline_graph
    for node, edges in graph.graph.items():
AttributeError: 'StateGraph' object has no attribute 'graph'
2025-07-11 16:01:06,902 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 16:01:06,905 [DEBUG] ← RESPONSE GET /stream status=500
2025-07-11 16:02:21,491 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 16:02:21,523 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 16:02:21,559 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:02:21,571 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:02:21,573 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 16:02:21,580 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 16:02:23,032 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 16:02:23,038 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 16:02:23,070 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:02:23,073 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 16:02:23,079 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:02:23,082 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 16:02:26,321 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 16:02:26,363 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 16:02:26,632] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:04:38,576] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:07:15,937] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:09:57,399] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 16:11:04,507 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:11:04,521 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:11:04,536 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 16:11:04,538 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
[2025-07-11 16:12:55,739] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:15:27,746] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 16:16:39,088 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 16:16:39,111 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 16:16:39,132 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:16:39,143 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:16:39,161 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 16:16:39,169 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 16:16:41,950 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:16:41,963 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 16:16:41,965 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:16:41,965 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 16:16:44,670 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 16:16:44,744 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 16:16:45,093] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:19:22,577] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:22:40,644] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:25:36,439] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:29:31,314] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:33:17,039] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:37:14,687] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 16:38:20,398 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 16:38:20,422 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 16:38:20,440 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:38:20,453 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:38:20,463 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 16:38:20,470 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 16:38:24,639 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 16:38:24,757 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 16:38:24,866] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:40:50,699] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:44:14,681] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
[2025-07-11 16:47:40,149] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 16:50:24,372 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 16:50:24,399 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 16:50:24,420 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:50:24,435 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:50:24,874 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 16:50:24,902 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 16:50:31,122 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 16:50:31,213 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 16:50:31,513] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 16:50:32,388 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 16:50:32,397 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 16:50:32,405 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 16:50:32,406 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 17:04:31,120 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 17:04:31,144 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 17:04:31,160 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 17:04:31,167 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 17:04:31,581 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 17:04:31,587 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 17:04:34,662 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 17:04:34,669 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 17:04:34,672 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 17:04:34,672 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 17:04:37,755 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 17:04:37,814 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 17:04:38,034] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 17:09:55,336 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 17:09:55,377 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 17:09:55,429 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 17:09:55,443 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 17:09:55,449 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 17:09:55,462 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 17:10:00,878 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 17:10:00,888 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 17:10:00,900 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 17:10:00,901 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 17:10:02,354 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 17:10:02,474 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 17:10:02,669] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 17:19:25,288 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 17:19:25,317 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 17:19:25,357 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 17:19:25,367 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 17:19:25,396 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 17:19:25,406 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 17:19:40,803 [DEBUG] → REQUEST GET /stream args={'lore': 'example_lore.json', 'thread_id': 'session-1'} form=[]
2025-07-11 17:19:40,893 [DEBUG] ← RESPONSE GET /stream status=200
[2025-07-11 17:19:41,078] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b-instruct-q5_K_M
2025-07-11 18:01:45,919 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:01:45,922 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:01:45,939 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:01:45,949 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:01:45,954 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:01:45,960 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:02:19,121 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:02:19,145 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:02:19,163 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:02:19,172 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:02:19,183 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:02:19,191 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:02:21,427 [DEBUG] → REQUEST GET /narrative/start args={} form=[]
2025-07-11 18:02:21,428 [DEBUG] ← RESPONSE GET /narrative/start status=405
2025-07-11 18:04:28,099 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:04:28,123 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:04:28,139 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:04:28,146 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:04:28,152 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:04:28,157 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:04:30,198 [DEBUG] → REQUEST GET /narrative/start args={} form=[]
2025-07-11 18:04:30,199 [DEBUG] ← RESPONSE GET /narrative/start status=405
2025-07-11 18:07:50,397 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:07:50,443 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:07:50,479 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:07:50,493 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:07:50,494 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:07:50,508 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:07:54,669 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:07:54,694 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:07:54,721 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:07:54,722 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:07:54,725 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:07:54,726 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-11 18:08:05,865 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:08:05,872 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:08:05,897 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:08:05,898 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:08:05,924 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:08:05,926 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:08:11,534 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:08:11,535 [ERROR] Exception on /narrative/start [POST]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/narrative_route.py", line 18, in start_narrative
    graph, state = get_pipeline_with_memory(thread_id)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/narrative_graph.py", line 128, in get_pipeline_with_memory
    graph = build_narrative_pipeline(checkpointer=saver)
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/graphs/narrative_graph.py", line 118, in build_narrative_pipeline
    builder.add_conditional_edges("NextStep", {True: "End", False: "NarrateStep"}, condition=is_finished)
TypeError: StateGraph.add_conditional_edges() got an unexpected keyword argument 'condition'
2025-07-11 18:08:11,551 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 18:08:11,552 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:10:01,695 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:10:01,721 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:10:01,740 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:10:01,750 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:10:01,758 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:10:01,766 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:10:03,503 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:10:03,516 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:10:03,537 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:10:03,538 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:10:03,543 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:10:03,545 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:10:06,666 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:10:06,770 [ERROR] Exception on /narrative/start [POST]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/narrative_route.py", line 20, in start_narrative
    graph.invoke(state)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2843, in invoke
    for chunk in self.stream(
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2427, in stream
    ) = self._defaults(
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2321, in _defaults
    raise ValueError(
ValueError: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id
2025-07-11 18:10:06,789 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 18:10:06,789 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:16:53,950 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:16:53,976 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:16:53,997 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:16:54,009 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:16:54,022 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:16:54,030 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:16:56,448 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:16:56,465 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:16:56,487 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:16:56,492 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:16:56,494 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:16:56,522 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:16:59,978 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:17:00,030 [ERROR] Exception on /narrative/start [POST]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/narrative_route.py", line 23, in start_narrative
    result_state = graph.invoke(base_state, configurable={"thread_id": thread_id})
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2843, in invoke
    for chunk in self.stream(
TypeError: Pregel.stream() got an unexpected keyword argument 'configurable'
2025-07-11 18:17:00,055 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 18:17:00,056 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:19:41,833 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:19:41,860 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:19:41,880 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:19:41,890 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:19:41,902 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:19:41,908 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:19:43,652 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:19:43,661 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:19:43,685 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:19:43,687 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:19:43,689 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:19:43,694 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:19:47,246 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:19:47,399 [ERROR] Exception on /narrative/start [POST]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/mnt/c/Users/paolo/ProgettoIAPDDL/PROGETTOIAPDDL/routes/narrative_route.py", line 16, in start_narrative
    result_state = graph.invoke(base_state)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2843, in invoke
    for chunk in self.stream(
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2427, in stream
    ) = self._defaults(
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py", line 2321, in _defaults
    raise ValueError(
ValueError: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id
2025-07-11 18:19:47,414 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-11 18:19:47,414 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:24:21,888 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:24:21,920 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:24:21,945 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:24:21,955 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:24:21,967 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:24:21,972 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:24:27,604 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:24:27,620 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:24:27,640 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:24:27,641 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:24:27,653 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:24:27,660 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:24:29,846 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:24:29,852 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:24:29,859 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 18:24:29,860 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 18:24:33,756 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:24:33,827 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:26:26,148 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:26:26,173 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:26:26,211 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:26:26,218 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:26:26,239 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:26:26,260 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:26:29,349 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:26:29,357 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:26:29,384 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:26:29,384 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:26:29,388 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:26:29,391 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:26:33,899 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:26:33,908 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 18:26:33,913 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 18:26:33,915 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:26:35,111 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:26:35,188 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:28:54,873 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:28:54,905 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:28:54,929 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:28:54,945 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:28:54,954 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:28:54,965 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:28:57,040 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:28:57,181 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:28:57,216 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:28:57,216 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:28:57,228 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:28:57,230 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:29:00,009 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:29:00,230 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:30:45,747 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:30:45,776 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:30:45,805 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:30:45,816 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:30:45,824 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:30:45,832 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:30:49,377 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:30:49,388 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:30:49,414 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:30:49,415 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:30:49,418 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:30:49,419 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:30:52,763 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:30:52,950 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:34:28,437 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:34:28,464 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:34:28,501 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:34:28,510 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:34:28,679 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:34:28,686 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:34:30,861 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:34:30,874 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:34:30,897 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:34:30,898 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:34:30,905 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:34:30,906 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:34:34,781 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:34:34,783 [DEBUG] ← RESPONSE POST /narrative/start status=400
2025-07-11 18:37:17,756 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:37:17,786 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:37:17,810 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:37:17,820 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:37:17,823 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:37:17,830 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:37:42,346 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:37:42,358 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:37:42,385 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:37:42,386 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:37:42,391 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:37:42,393 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-11 18:37:50,643 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:37:50,832 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:39:57,712 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:39:57,737 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:39:57,754 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:39:57,761 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:39:57,779 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:39:57,785 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:39:59,421 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:39:59,450 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:39:59,473 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:39:59,474 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:39:59,499 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:39:59,504 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:40:02,982 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
2025-07-11 18:40:03,252 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:41:52,903 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:41:52,931 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:41:52,952 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:41:52,962 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:41:52,970 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:41:52,977 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:41:56,238 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:41:56,246 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:41:56,274 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:41:56,275 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:41:56,278 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:41:56,280 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:41:59,632 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
[2025-07-11 18:41:59,825] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 18:42:50,649 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:45:21,417 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:45:21,443 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:45:21,467 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:45:21,485 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:45:21,495 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:45:21,505 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:45:28,068 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:45:28,087 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:45:28,112 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:45:28,115 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:45:28,126 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:45:28,128 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:45:31,166 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
[2025-07-11 18:45:31,455] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 18:45:52,870 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:51:03,839 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:51:03,864 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:51:03,882 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:51:03,890 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:51:03,902 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:51:03,908 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:51:06,126 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:51:06,138 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:51:06,177 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:51:06,178 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:51:06,183 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:51:06,185 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:51:10,192 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
[2025-07-11 18:51:10,406] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 18:52:07,850 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 18:59:00,048 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 18:59:00,068 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 18:59:00,088 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:59:00,102 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:59:00,479 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 18:59:00,507 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 18:59:02,831 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 18:59:02,846 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 18:59:02,871 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:59:02,872 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 18:59:02,877 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:59:02,878 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 18:59:11,443 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 18:59:11,449 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 18:59:11,456 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 18:59:11,458 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 18:59:12,728 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
[2025-07-11 18:59:12,905] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:00:04,108] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:00:45,231] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:01:28,393] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:02:09,590] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:02:55,945 [DEBUG] ← RESPONSE POST /narrative/start status=500
2025-07-11 19:05:46,721 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:05:46,743 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:05:46,765 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:05:46,776 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:05:46,813 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:05:46,820 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:09:34,213 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:09:34,238 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:09:34,261 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:09:34,270 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:09:34,271 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:09:34,277 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:09:36,832 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:09:36,841 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:09:36,866 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:09:36,867 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:09:36,871 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:09:36,873 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-11 19:09:42,755 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752253782413', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:09:42,756 [DEBUG] ← RESPONSE GET /narrative/stream status=404
2025-07-11 19:11:31,436 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:11:31,463 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:11:31,485 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:11:31,495 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:11:31,526 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:11:31,533 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:11:41,024 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:11:41,065 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:11:41,093 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:11:41,095 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:11:41,101 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:11:41,104 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 19:11:47,717 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752253907278', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:11:47,718 [DEBUG] ← RESPONSE GET /narrative/stream status=404
2025-07-11 19:12:57,657 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:12:57,683 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:12:57,705 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:12:57,714 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:12:58,092 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:12:58,133 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:13:00,357 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:13:00,397 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:13:00,443 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:13:00,444 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:13:00,450 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:13:00,452 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 19:13:03,811 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752253983564', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:13:03,896 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:13:04,007] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:14:01,850] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:14:43,808] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:15:24,022] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:20:04,848 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:20:04,871 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:20:04,889 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:20:04,904 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:20:04,916 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:20:04,923 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:20:07,026 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:20:07,036 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:20:07,059 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:20:07,061 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:20:07,064 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:20:07,070 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 19:20:10,401 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752254410165', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:20:10,480 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:20:10,586] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:20:52,004] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:21:34,239] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:22:32,220 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:22:32,246 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:22:32,265 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:22:32,277 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:22:32,284 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:22:32,293 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:22:37,426 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:22:37,435 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:22:37,459 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:22:37,461 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:22:37,466 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:22:37,470 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-11 19:22:40,819 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752254561085', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:22:40,932 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:22:41,108] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:23:06,061 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:23:06,071 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:23:06,089 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 19:23:06,090 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 19:23:09,624 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752254589704', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:23:09,687 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:23:09,748] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:24:10,746] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:24:54,089] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:25:45,137] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:26:39,540] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:29:35,009 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:29:35,034 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:29:35,053 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:29:35,065 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:29:35,076 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:29:35,088 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:29:37,765 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:29:37,773 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:29:37,798 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:29:37,801 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:29:37,806 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:29:37,808 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-11 19:29:40,712 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752254980646', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:29:40,766 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:29:40,969] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:30:24,373] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:31:13,709] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:31:58,305] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:32:44,050] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:35:15,846 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:35:15,872 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:35:15,891 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:35:15,901 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:35:16,250 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:35:16,277 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:35:18,172 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:35:18,188 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:35:18,215 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:35:18,217 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:35:18,221 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:35:18,222 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-11 19:35:22,887 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:35:22,895 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:35:22,896 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 19:35:22,898 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 19:35:24,343 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752255324711', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:35:24,482 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:35:24,618] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:36:09,815] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:37:01,575] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:37:48,323] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:38:33,278] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:42:26,222 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:42:26,243 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:42:26,264 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:42:26,274 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:42:26,385 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:42:26,391 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:42:28,995 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:42:29,007 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:42:29,038 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:42:29,039 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:42:29,042 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:42:29,043 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 19:42:32,465 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:42:32,473 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 19:42:32,473 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-11 19:42:32,474 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:42:34,697 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752255755072', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:42:34,732 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:42:35,690] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:43:21,188] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:44:04,014] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:44:50,714] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:45:37,967] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:51:04,548 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:51:04,568 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:51:04,587 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:51:04,595 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:51:04,613 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:51:04,620 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:51:07,908 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:51:07,918 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:51:07,944 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:51:07,945 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:51:07,949 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:51:07,950 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 19:51:11,777 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752256271800', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:51:11,833 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:51:12,004] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:51:52,082] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:52:40,358] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:53:23,598] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:54:16,377 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-11 19:54:16,406 [DEBUG] ← RESPONSE GET / status=200
2025-07-11 19:54:16,431 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:54:16,438 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:54:16,450 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-11 19:54:16,457 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-11 19:54:21,683 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-11 19:54:21,698 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-11 19:54:21,728 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:54:21,730 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-11 19:54:21,733 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:54:21,737 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-11 19:54:24,658 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752256464481', 'lore': 'example_lore.json'} form=[]
2025-07-11 19:54:24,708 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-11 19:54:24,829] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:55:07,394] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-11 19:55:28,120] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-11 19:55:37,365 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-11 19:55:37,378 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-11 19:55:37,391 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-11 19:55:37,392 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 10:39:04,267 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 10:39:04,319 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 10:39:04,383 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 10:39:04,400 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 10:39:04,410 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 10:39:04,426 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 10:39:10,911 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 10:39:10,935 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 10:39:10,986 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 10:39:10,988 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 10:39:10,994 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 10:39:10,997 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 10:39:15,104 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 10:39:15,133 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 10:39:15,134 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 10:39:15,141 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 10:39:19,834 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752309559987', 'lore': 'example_lore.json'} form=[]
2025-07-12 10:39:19,937 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 10:39:20,349] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 10:40:48,473] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 10:41:40,261] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 10:42:57,094] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 10:44:05,317] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:03:23,549 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:03:23,582 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:03:23,629 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:03:23,643 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:03:23,693 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:03:23,709 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:03:26,173 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 11:03:26,210 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 11:03:26,282 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:03:26,286 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 11:03:26,297 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:03:26,301 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 11:03:30,445 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752311010425', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:03:30,594 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:03:30,994] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:03:33,987 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:03:33,998 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:03:34,005 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:03:34,006 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:03:50,366 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752311030352', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:03:50,428 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:03:50,506] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:04:21,105 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752311030352', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:04:21,185 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:04:21,234] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:35:52,832 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:35:52,887 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:35:52,943 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:35:52,966 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:35:52,970 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:35:52,977 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:35:56,154 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 11:35:56,182 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 11:35:56,243 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:35:56,247 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 11:35:56,257 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:35:56,264 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 11:37:55,876 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:37:55,933 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:37:55,981 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:37:56,002 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:37:56,003 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:37:56,032 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:37:58,819 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:37:58,828 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:37:58,979 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:37:58,980 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:38:00,282 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 11:38:00,320 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 11:38:00,373 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:38:00,375 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:38:00,393 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:38:00,407 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 11:38:00,445 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 11:38:00,477 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 11:38:06,762 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752313086738', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:38:06,909 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:38:07,302] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:39:39,390] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:40:56,611] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:42:58,599 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:42:58,651 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:42:58,715 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:42:58,745 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:42:58,747 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:42:58,768 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:43:00,815 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 11:43:00,866 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 11:43:00,967 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:43:00,969 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 11:43:00,986 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:43:00,997 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 11:43:04,518 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:43:04,528 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:43:04,536 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:43:04,537 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:43:07,322 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752313387299', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:43:07,471 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:43:07,840] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:44:25,862] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:46:05,244] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:47:09,681 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:47:09,736 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:47:09,807 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:47:09,824 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:47:09,834 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:47:09,853 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:47:12,747 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:47:12,770 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:47:12,780 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:47:12,783 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:47:14,636 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 11:47:14,676 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 11:47:14,742 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:47:14,743 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:47:14,764 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:47:14,780 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 11:47:14,845 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 11:47:14,866 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 11:47:18,179 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752313638155', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:47:18,362 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:47:18,790] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:48:31,453] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:49:44,259] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:51:18,885] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:52:55,247] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 11:54:37,519] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 11:57:32,858 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:57:32,901 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:57:32,941 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:57:32,957 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:57:32,978 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:57:32,996 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:57:34,173 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 11:57:34,177 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 11:57:34,201 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:57:34,209 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:57:34,213 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 11:57:34,222 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 11:57:36,439 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 11:57:36,451 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 11:57:36,507 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:57:36,508 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 11:57:36,514 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:57:36,516 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 11:57:42,558 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 11:57:42,566 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 11:57:42,575 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 11:57:42,576 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 11:57:44,316 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752314264293', 'lore': 'example_lore.json'} form=[]
2025-07-12 11:57:44,430 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 11:57:44,892] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:02:16,199 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:02:16,225 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:02:16,250 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:02:16,266 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:02:16,281 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:02:16,289 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:02:19,822 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:02:19,855 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:02:19,890 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:02:19,892 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:02:19,903 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:02:19,907 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:02:22,769 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:02:22,774 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:02:22,778 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:02:22,781 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:02:26,154 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752314546143', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:02:26,283 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:02:26,493] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:04:33,248 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:04:33,274 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:04:33,293 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:04:33,306 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:04:33,317 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:04:33,332 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:04:35,569 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:04:35,577 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:04:35,612 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:04:35,613 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:04:35,622 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:04:35,626 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:04:40,768 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:04:40,780 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:04:40,782 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:04:40,784 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:04:42,164 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752314682147', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:04:42,258 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:04:42,505] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:05:55,704 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:05:55,737 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:05:55,763 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:05:55,773 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:05:55,775 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:05:55,782 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:05:57,774 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:05:57,798 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:05:57,831 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:05:57,832 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:05:57,837 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:05:57,842 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:06:00,022 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:06:00,029 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:06:00,030 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:06:00,033 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:06:02,736 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752314762727', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:06:02,805 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:06:02,973] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:08:16,684 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:08:16,712 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:08:16,743 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:08:16,754 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:08:17,002 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:08:17,009 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:08:19,110 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:08:19,129 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:08:19,156 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:08:19,157 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:08:19,162 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:08:19,164 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:08:21,199 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:08:21,206 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:08:21,207 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:08:21,209 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:08:25,679 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752314905665', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:08:25,796 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:08:25,954] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:08:44,714] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:09:31,713] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:10:18,757] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:11:12,648 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:11:12,679 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:11:12,710 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:11:12,723 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:11:12,730 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:11:12,744 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:11:14,776 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:11:14,788 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:11:14,820 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:11:14,821 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:11:14,826 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:11:14,830 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:11:16,853 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:11:16,854 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:11:16,867 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:11:16,874 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:11:20,550 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752315080534', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:11:20,652 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:11:20,789] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:12:04,824] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:12:50,002] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:13:51,294 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:13:51,330 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:13:51,363 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:13:51,375 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:13:51,405 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:13:51,417 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:13:53,764 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:13:53,790 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:13:53,822 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:13:53,823 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:13:53,829 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:13:53,832 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:13:57,960 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752315237946', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:13:58,071 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:13:58,257] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:14:46,485] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:15:43,937 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:15:43,963 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:15:43,984 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:15:43,998 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:15:44,016 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:15:44,027 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:15:46,085 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:15:46,101 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:15:46,133 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:15:46,134 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:15:46,142 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:15:46,148 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 12:15:49,941 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752315349884', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:15:49,991 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:15:50,126] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:16:35,981] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:17:22,294 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:17:22,317 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:17:22,340 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:17:22,352 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:17:22,362 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:17:22,370 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:17:24,388 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:17:24,407 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:17:24,433 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:17:24,434 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:17:24,438 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:17:24,439 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:17:28,304 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752315448294', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:17:28,431 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:17:28,594] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:18:19,621] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:26:08,542 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:26:08,568 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:26:08,908 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:26:08,918 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:26:08,929 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:26:08,938 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:26:09,192 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-12 12:26:09,193 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-12 12:26:09,204 [DEBUG] → REQUEST GET /favicon.ico args={} form=[]
2025-07-12 12:26:09,204 [DEBUG] ← RESPONSE GET /favicon.ico status=404
2025-07-12 12:26:12,405 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:26:12,419 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:26:12,438 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:26:12,439 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:26:12,444 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:26:12,448 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 12:26:16,137 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752315976115', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:26:16,238 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:26:16,442] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:27:08,050] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:27:34,262 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:27:34,273 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:27:34,296 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:27:34,299 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:35:40,039 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:35:40,062 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:35:40,078 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:35:40,089 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:35:40,090 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:35:40,095 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:35:42,478 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:35:42,524 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:35:42,548 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:35:42,549 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:35:42,559 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:35:42,567 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 12:35:46,650 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:35:46,659 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:35:46,661 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 12:35:46,663 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 12:35:48,839 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752316548185', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:35:48,928 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:35:49,223] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:35:56,897 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752316548185', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:35:56,929 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:35:57,052] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 12:37:23,052 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 12:37:23,075 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 12:37:23,091 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:37:23,102 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:37:23,103 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 12:37:23,109 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 12:37:25,049 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 12:37:25,057 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 12:37:25,085 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 12:37:25,085 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 12:37:25,091 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 12:37:25,092 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 12:37:29,108 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752316648441', 'lore': 'example_lore.json'} form=[]
2025-07-12 12:37:29,168 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 12:37:29,337] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:37:47,405] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:38:35,685] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 12:39:18,067] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 13:38:43,871 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 13:38:43,889 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 13:38:43,905 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:38:43,912 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:38:43,919 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 13:38:43,925 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 13:38:46,684 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 13:38:46,691 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 13:38:46,711 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:38:46,712 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 13:38:46,717 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:38:46,718 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 13:38:51,746 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:38:51,752 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:38:51,756 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 13:38:51,757 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 13:38:53,037 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752320332977', 'lore': 'example_lore.json'} form=[]
2025-07-12 13:38:53,087 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 13:38:53,244] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:39:43,949] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:40:31,850] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 13:41:47,581 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 13:41:47,603 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 13:41:47,618 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:41:47,624 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:41:47,627 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 13:41:47,634 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 13:41:52,556 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 13:41:52,563 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 13:41:52,589 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:41:52,590 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 13:41:52,592 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:41:52,593 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 13:41:58,582 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:41:58,587 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:41:58,594 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 13:41:58,594 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 13:42:00,083 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752320519612', 'lore': 'example_lore.json'} form=[]
2025-07-12 13:42:00,121 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 13:42:00,262] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:42:39,518] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:43:21,276] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:44:09,697] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:44:51,419] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:45:33,871] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 13:47:39,918 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 13:47:39,939 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 13:47:39,957 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:47:39,966 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:47:40,008 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 13:47:40,012 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 13:47:42,842 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 13:47:42,852 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 13:47:42,869 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:47:42,870 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 13:47:42,873 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:47:42,874 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 13:47:47,683 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:47:47,690 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:47:47,693 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 13:47:47,694 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 13:47:49,302 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752320869575', 'lore': 'example_lore.json'} form=[]
2025-07-12 13:47:49,363 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 13:47:49,509] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:48:32,476] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:49:13,620] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:49:54,754] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:50:31,313] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:51:21,783] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 13:54:32,863 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 13:54:32,886 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 13:54:32,903 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:54:32,915 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:54:32,929 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 13:54:32,936 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 13:54:35,838 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 13:54:35,847 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 13:54:35,870 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:54:35,871 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 13:54:35,878 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:54:35,879 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 13:54:40,179 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752321279494', 'lore': 'example_lore.json'} form=[]
2025-07-12 13:54:40,247 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 13:54:40,351] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 13:54:44,906 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 13:54:44,912 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 13:54:44,925 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 13:54:44,926 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 13:54:46,998 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752321286539', 'lore': 'example_lore.json'} form=[]
2025-07-12 13:54:47,033 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 13:54:47,102] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:55:59,338] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 13:56:10,057 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752321286539', 'lore': 'example_lore.json', 'feedback': 'ciao'} form=[]
2025-07-12 13:56:10,098 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 13:56:10,134] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:57:05,641] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:57:54,185] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:58:46,333] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 13:59:36,084] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:00:18,890] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 14:02:09,990 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 14:02:10,010 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 14:02:10,026 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:02:10,032 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:02:10,041 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 14:02:10,047 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 14:02:12,036 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 14:02:12,056 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 14:02:12,077 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:02:12,077 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 14:02:12,080 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:02:12,081 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 14:02:16,052 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:02:16,059 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:02:16,063 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:02:16,064 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:02:17,321 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752321737553', 'lore': 'example_lore.json'} form=[]
2025-07-12 14:02:17,392 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 14:02:17,522] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:02:59,691] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:03:47,705] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:04:34,521] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:05:26,761] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 14:06:25,435 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 14:06:25,458 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 14:06:25,479 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:06:25,489 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:06:25,497 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 14:06:25,503 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 14:06:27,786 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 14:06:27,798 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 14:06:27,820 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:06:27,821 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 14:06:27,825 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:06:27,827 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 14:06:31,354 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:06:31,359 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:06:31,363 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:06:31,368 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:06:32,892 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752321992669', 'lore': 'example_lore.json'} form=[]
2025-07-12 14:06:32,946 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 14:06:33,063] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:07:37,192] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:08:42,551] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 14:11:09,870 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 14:11:09,891 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 14:11:09,906 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:11:09,914 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:11:10,027 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 14:11:10,034 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 14:11:11,918 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 14:11:11,932 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 14:11:11,950 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:11:11,951 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 14:11:11,953 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:11:11,954 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 14:11:16,350 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:11:16,356 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:11:16,364 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:11:16,365 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:11:17,505 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752322277889', 'lore': 'example_lore.json'} form=[]
2025-07-12 14:11:17,570 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 14:11:17,691] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:12:00,123] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:12:19,413] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:13:06,905] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:13:52,786] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:14:39,211] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 14:16:06,171 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 14:16:06,192 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 14:16:06,214 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:16:06,222 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:16:06,230 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 14:16:06,237 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 14:16:08,271 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 14:16:08,280 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 14:16:08,301 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:16:08,306 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 14:16:08,306 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:16:08,312 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 14:16:12,229 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:16:12,240 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:16:12,240 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:16:12,250 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:16:13,461 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752322573609', 'lore': 'example_lore.json'} form=[]
2025-07-12 14:16:13,519 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 14:16:13,639] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:17:11,163] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:17:56,918] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:18:42,955] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:19:33,755] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:20:21,343] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 14:24:42,518 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 14:24:42,540 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 14:24:42,558 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:24:42,567 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:24:42,611 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 14:24:42,641 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 14:24:47,222 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:24:47,223 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:24:47,223 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:24:47,236 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 14:24:48,087 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 14:24:48,107 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 14:24:48,126 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:24:48,127 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:24:48,135 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:24:48,141 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 14:24:48,179 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 14:24:48,188 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 14:24:51,754 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752323091112', 'lore': 'example_lore.json'} form=[]
2025-07-12 14:24:51,795 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 14:24:51,898] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:25:34,318] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:26:28,411] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:27:20,997] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 14:28:13,378 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 14:28:13,396 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 14:28:13,416 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 14:28:13,416 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 14:28:13,417 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 14:28:13,423 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 14:28:13,497 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 14:28:13,506 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 14:28:16,940 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752323296261', 'lore': 'example_lore.json'} form=[]
2025-07-12 14:28:16,994 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 14:28:17,108] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:29:01,035] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:29:25,873] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:30:30,993] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
[2025-07-12 14:31:27,686] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 15:33:39,473 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:33:39,499 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:33:39,528 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:33:39,540 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:33:39,554 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:33:39,562 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:33:42,328 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:33:42,336 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:33:42,345 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:33:42,346 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:33:44,246 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:33:44,264 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:33:44,300 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:33:44,301 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:33:44,316 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:33:44,324 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 15:33:44,350 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:33:44,358 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 15:33:49,255 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752327228459', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:33:49,395 [DEBUG] ← RESPONSE GET /narrative/stream status=200
2025-07-12 15:37:11,849 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:37:11,877 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:37:11,909 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:37:11,921 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:37:11,931 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:37:11,944 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:37:13,929 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:37:13,953 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:37:13,998 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:37:14,000 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:37:14,009 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:37:14,012 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 15:37:18,267 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752327437780', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:37:18,424 [ERROR] Exception on /narrative/stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1212, in make_response
    raise TypeError(
TypeError: The view function for 'narrative.narrative_stream' did not return a valid response. The function either returned None or ended without a return statement.
2025-07-12 15:37:18,449 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-12 15:37:18,450 [DEBUG] ← RESPONSE GET /narrative/stream status=500
2025-07-12 15:39:20,359 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:39:20,390 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:39:20,426 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:39:20,437 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:39:20,439 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:39:20,445 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:39:24,310 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:39:24,334 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:39:24,376 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:39:24,378 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:39:24,387 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:39:24,392 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 15:39:28,334 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:39:28,345 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:39:28,355 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:39:28,356 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:39:29,493 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752327568925', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:39:29,629 [ERROR] Exception on /narrative/stream [GET]
Traceback (most recent call last):
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "/mnt/c/Users/paolo/PROGETTOIAPDDL/.venv/lib/python3.10/site-packages/flask/app.py", line 1212, in make_response
    raise TypeError(
TypeError: The view function for 'narrative.narrative_stream' did not return a valid response. The function either returned None or ended without a return statement.
2025-07-12 15:39:29,641 [ERROR] Errore interno: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-07-12 15:39:29,643 [DEBUG] ← RESPONSE GET /narrative/stream status=500
2025-07-12 15:41:07,697 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:41:07,724 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:41:07,757 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:41:07,766 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:41:07,842 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:41:07,852 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:41:17,146 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:41:17,182 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:41:17,236 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:41:17,238 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:41:17,245 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:41:17,248 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 15:41:21,229 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:41:21,240 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:41:21,241 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:41:21,241 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:41:22,359 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752327682239', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:41:22,503 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 15:41:22,921] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 15:47:30,065 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:47:30,088 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:47:30,112 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:47:30,123 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:47:30,134 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:47:30,144 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:47:31,924 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:47:31,956 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:47:32,004 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:47:32,005 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:47:32,012 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:47:32,014 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 15:47:37,750 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:47:37,757 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:47:37,775 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:47:37,776 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:47:39,046 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328059442', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:47:39,174 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 15:47:39,488] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 15:53:09,714 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:53:09,744 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:53:09,776 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:53:09,788 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:53:09,802 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:53:09,813 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:53:11,682 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:53:11,707 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:53:11,752 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:53:11,755 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:53:11,760 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:53:11,764 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 15:53:16,407 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328396681', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:53:16,549 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 15:53:16,925] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 15:53:21,371 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:53:21,382 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:53:21,402 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:53:21,404 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:53:24,742 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328403900', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:53:24,793 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 15:53:24,876] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 15:57:14,450 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 15:57:14,482 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 15:57:14,526 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:57:14,538 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:57:14,551 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 15:57:14,562 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 15:57:18,683 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 15:57:18,710 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 15:57:18,760 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:57:18,763 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 15:57:18,768 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:57:18,771 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 15:57:23,680 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328642969', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:57:23,821 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 15:57:24,144] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 15:57:31,250 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 15:57:31,260 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 15:57:31,270 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 15:57:31,274 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 15:57:33,555 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328653287', 'lore': 'example_lore.json'} form=[]
2025-07-12 15:57:33,615 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 15:57:33,701] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:01:06,223 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:01:06,258 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:01:06,292 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:01:06,309 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 16:01:06,318 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:01:06,331 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:01:08,386 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:01:08,411 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:01:08,459 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:01:08,460 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:01:08,467 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:01:08,469 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:01:11,615 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328872054', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:01:11,755 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:01:12,174] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:01:20,431 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:01:20,441 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:01:20,450 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:01:20,451 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:01:21,734 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752328881128', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:01:21,782 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:01:21,862] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:06:06,213 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:06:06,236 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:06:06,259 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:06:06,271 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:06:06,284 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:06:06,291 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:06:08,238 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:06:08,259 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:06:08,298 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:06:08,301 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:06:08,304 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:06:08,307 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 16:06:12,583 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:06:12,592 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:06:12,598 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:06:12,599 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:06:13,792 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752329174193', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:06:13,942 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:06:14,221] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:12:12,705 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:12:12,749 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:12:12,789 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:12:12,800 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:12:12,820 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:12:12,830 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:12:14,469 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:12:14,493 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:12:14,558 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:12:14,559 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:12:14,570 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:12:14,576 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 16:12:20,332 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:12:20,350 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:12:20,359 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:12:20,362 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:12:21,429 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752329541856', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:12:21,521 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:12:21,761] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:16:17,507 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:16:17,551 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:16:17,603 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:16:17,618 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:16:17,637 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:16:17,649 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:16:19,104 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:16:19,112 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:16:19,143 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:16:19,152 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:16:19,153 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:16:19,161 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:16:21,551 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:16:21,567 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:16:21,604 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:16:21,606 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:16:21,612 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:16:21,614 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:16:26,913 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:16:26,922 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:16:26,928 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:16:26,929 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:16:29,752 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752329788935', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:16:29,867 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:16:30,159] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:22:10,950 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:22:10,972 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:22:10,995 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:22:11,006 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:22:11,018 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:22:11,025 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:22:15,004 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:22:15,035 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:22:15,090 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:22:15,094 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:22:15,102 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:22:15,107 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:22:18,868 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:22:18,883 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:22:18,903 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:22:18,904 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:22:19,925 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:22:20,046 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:22:20,353] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:23:43,058 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:23:43,146 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:23:43,262] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:24:17,799 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:24:17,850 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:24:17,879] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:25:00,370 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:25:00,424 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:25:00,456] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:25:41,404 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:25:41,517 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:25:41,570] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:26:21,276 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:26:21,327 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:26:21,367] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:27:17,981 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:27:18,045 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:27:18,078] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:27:56,011 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:27:56,087 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:27:56,129] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:29:16,762 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330139691', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:29:16,824 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:29:17,094] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:29:23,166 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:29:23,199 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:29:23,251 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:29:23,267 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:29:23,269 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:29:23,279 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:29:26,730 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:29:26,752 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:29:26,819 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:29:26,821 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:29:26,828 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:29:26,832 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:29:47,132 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:29:47,215 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:29:47,340] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:31:04,782 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:31:04,859 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:31:04,916] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:31:38,816 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:31:38,896 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:31:38,991] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:31:58,365 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:31:58,412 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:31:58,442] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:45:27,633 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:45:29,207 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:45:29,614] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:46:31,911 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:46:31,972 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:46:32,000] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:47:10,684 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:47:10,775 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:47:10,820] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:47:45,025 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:47:45,103 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:47:45,147] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:48:21,783 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:48:21,833 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:48:21,882] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:49:00,642 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:49:00,702 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:49:00,736] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:50:02,852 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:50:02,957 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:50:03,312] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:50:37,131 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:50:37,212 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:50:37,259] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:51:23,512 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:51:23,595 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:51:23,630] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:52:00,727 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:52:00,787 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:52:00,823] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:52:39,075 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:52:39,134 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 16:52:39,175] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:53:43,359 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752330587281', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:53:43,360 [DEBUG] ← RESPONSE GET /narrative/stream status=404
2025-07-12 16:53:49,311 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:53:49,338 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:53:49,368 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:53:49,377 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:53:49,396 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:53:49,404 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 16:53:51,555 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:53:51,578 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:53:51,621 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:53:51,623 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:53:51,630 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:53:51,635 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:53:53,791 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:53:53,800 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:53:53,803 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:53:53,805 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:53:56,047 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:53:56,053 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:53:56,082 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:53:56,083 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:53:56,095 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:53:56,106 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 16:53:56,133 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:53:56,145 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:54:00,672 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332040885', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:54:00,785 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:54:01,356] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:54:33,159 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332040885', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:54:33,266 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:54:33,373] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:55:59,826 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 16:55:59,882 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 16:55:59,927 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:55:59,931 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:55:59,939 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:55:59,950 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 16:56:00,062 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 16:56:00,074 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=200
2025-07-12 16:56:11,490 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 16:56:11,512 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 16:56:11,548 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:56:11,548 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:56:11,561 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:56:11,567 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 16:56:11,600 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 16:56:11,609 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 16:56:24,498 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:56:24,500 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:56:24,545 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:56:24,551 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:56:24,552 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:56:24,556 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:56:27,836 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:56:27,837 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:56:27,848 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 16:56:27,859 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 16:56:27,872 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 16:56:27,873 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 16:56:31,850 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:56:31,959 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:56:32,392] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:57:07,525 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:57:07,602 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:57:07,669] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:57:41,889 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:57:41,960 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:57:42,012] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:58:15,937 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:58:16,023 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:58:16,076] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:58:57,753 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:58:57,795 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:58:57,816] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 16:59:35,848 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 16:59:35,914 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 16:59:35,963] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:00:06,453 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:00:06,512 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:00:06,550] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:00:38,673 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:00:38,754 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:00:38,806] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:01:16,922 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:01:17,013 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:01:17,067] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:01:54,663 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:01:54,705 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:01:54,827] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:02:23,198 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:02:23,277 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:02:23,313] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:06:57,054 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:06:57,166 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:06:57,296] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:07:03,370 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:07:03,405 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:07:03,443 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:07:03,457 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:07:03,463 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:07:03,475 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:07:21,021 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:07:21,048 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:07:21,073] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:07:42,548 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:07:42,591 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:07:42,616] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:08:02,052 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:08:02,099 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:08:02,117] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:08:24,900 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:08:24,937 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:08:24,960] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:08:50,250 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:08:50,289 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:08:50,317] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:09:17,385 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:09:17,429 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:09:17,441] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:09:36,669 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:09:36,695 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=200
[2025-07-12 17:09:36,730] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:10:16,936 [DEBUG] → REQUEST GET /narrative/stream_internal args={'thread_id': 'narrative-1752332191473', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:10:16,943 [DEBUG] ← RESPONSE GET /narrative/stream_internal status=404
2025-07-12 17:10:19,082 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:10:19,112 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:10:19,131 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:10:19,140 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:10:19,156 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:10:19,164 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:10:22,839 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:10:22,856 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:10:22,875 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:10:22,876 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:10:22,881 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:10:22,882 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:10:24,526 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:10:24,535 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:10:24,536 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:10:24,540 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:10:27,573 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:10:27,635 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:10:27,784] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:10:52,024 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:10:52,059 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:10:52,081] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:11:14,779 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:11:14,803 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:11:14,816] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:11:38,924 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:11:38,940 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:11:38,950] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:12:05,142 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:12:05,167 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:12:05,185] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:12:31,514 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:12:31,544 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:12:31,559] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:12:57,701 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:12:57,721 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:12:57,731] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:13:27,232 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333026848', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:13:27,251 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:13:27,268] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:15:08,680 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:15:08,712 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:15:08,736 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:15:08,747 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:15:08,755 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:15:08,770 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:15:10,844 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:15:10,869 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:15:10,889 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:15:10,889 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:15:10,921 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:15:10,924 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:15:15,087 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:15:15,094 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:15:15,095 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:15:15,095 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:15:18,142 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333318691', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:15:18,198 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:15:18,357] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:17:01,983 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:17:02,010 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:17:02,027 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:17:02,037 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:17:02,047 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:17:02,058 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:17:06,520 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:17:06,525 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:17:06,534 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:17:06,535 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:17:07,588 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:17:07,612 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:17:07,634 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:17:07,634 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:17:07,644 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:17:07,648 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 17:17:07,660 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:17:07,669 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:18:01,113 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:18:01,137 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:18:01,153 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:18:01,161 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:18:01,175 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:18:01,184 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:18:03,203 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:18:03,214 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:18:03,217 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:18:03,231 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:18:04,770 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:18:04,793 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:18:04,833 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:18:04,834 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:18:04,846 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:18:04,858 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 17:18:04,884 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:18:04,897 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:20:34,948 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:20:35,074 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:20:35,106 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:20:35,116 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:20:35,121 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:20:35,133 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:20:37,782 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:20:37,792 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:20:37,794 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:20:37,794 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:20:38,698 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:20:38,760 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:20:38,817 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:20:38,818 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:20:38,828 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:20:38,833 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 17:20:38,865 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:20:38,873 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:20:47,288 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:20:47,301 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:20:47,319 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:20:47,320 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:20:47,326 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:20:47,330 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 17:20:47,366 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:20:47,380 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:23:16,424 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:23:16,443 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:23:16,457 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:23:16,465 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:23:16,506 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:23:16,510 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:23:23,913 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:23:23,922 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:23:23,938 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:23:23,939 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:23:23,943 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:23:23,946 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:23:25,503 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:23:25,508 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:23:25,514 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:23:25,515 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:24:11,467 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:24:11,489 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:24:11,503 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:24:11,504 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:24:11,506 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:24:11,515 [DEBUG] ← RESPONSE GET /static/style.css status=200
2025-07-12 17:24:11,542 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:24:11,550 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:24:15,026 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:24:15,038 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:24:15,050 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:24:15,054 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:24:15,065 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:24:15,071 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:24:18,132 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:24:18,134 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:24:18,152 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:24:18,153 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:24:18,159 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:24:18,161 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=304
2025-07-12 17:24:20,623 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
[2025-07-12 17:24:20,868] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:25:15,541 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:25:15,543 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:25:15,546 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:25:15,558 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:25:16,893 [DEBUG] → REQUEST POST /narrative/start args={} form=[]
[2025-07-12 17:25:17,040] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:25:29,813 [DEBUG] → REQUEST GET /narrative/start args={} form=[]
2025-07-12 17:25:29,815 [DEBUG] ← RESPONSE GET /narrative/start status=405
2025-07-12 17:25:51,146 [DEBUG] ← RESPONSE POST /narrative/start status=200
2025-07-12 17:25:51,166 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333916992', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:25:51,210 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:25:51,271] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:26:19,587 [DEBUG] ← RESPONSE POST /narrative/start status=200
2025-07-12 17:26:19,608 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752333916992', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:26:19,651 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:26:19,679] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:29:30,699 [DEBUG] → REQUEST GET / args={} form=[]
2025-07-12 17:29:30,724 [DEBUG] ← RESPONSE GET / status=200
2025-07-12 17:29:30,747 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:29:30,757 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:29:30,765 [DEBUG] → REQUEST GET /static/js/pipeline.js args={} form=[]
2025-07-12 17:29:30,771 [DEBUG] ← RESPONSE GET /static/js/pipeline.js status=304
2025-07-12 17:29:32,710 [DEBUG] → REQUEST GET /narrative/ args={} form=[]
2025-07-12 17:29:32,727 [DEBUG] ← RESPONSE GET /narrative/ status=200
2025-07-12 17:29:32,751 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:29:32,752 [DEBUG] → REQUEST GET /static/js/narrative.js args={} form=[]
2025-07-12 17:29:32,756 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:29:32,761 [DEBUG] ← RESPONSE GET /static/js/narrative.js status=200
2025-07-12 17:29:34,529 [DEBUG] → REQUEST GET /static/style.css args={} form=[]
2025-07-12 17:29:34,530 [DEBUG] → REQUEST GET /.well-known/appspecific/com.chrome.devtools.json args={} form=[]
2025-07-12 17:29:34,532 [DEBUG] ← RESPONSE GET /.well-known/appspecific/com.chrome.devtools.json status=404
2025-07-12 17:29:34,546 [DEBUG] ← RESPONSE GET /static/style.css status=304
2025-07-12 17:29:37,572 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752334177372', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:29:37,628 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:29:37,762] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:30:13,226 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752334177372', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:30:13,263 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:30:13,282] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
2025-07-12 17:30:42,114 [DEBUG] → REQUEST GET /narrative/stream args={'thread_id': 'narrative-1752334177372', 'lore': 'example_lore.json'} form=[]
2025-07-12 17:30:42,168 [DEBUG] ← RESPONSE GET /narrative/stream status=200
[2025-07-12 17:30:42,201] INFO: 📤 Invio prompt a Ollama con modello: llama3:8b
