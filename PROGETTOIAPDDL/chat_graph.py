from typing import Annotated
import json
import os

from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import tools_condition, ToolNode
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage
from langchain_ollama import ChatOllama
from langchain_core.tools import tool

from game.generator import build_prompt_from_lore, ask_ollama, extract_between
from game.validator import validate_pddl
from agent.reflection_agent import refine_pddl
from game.utils import save_text_file


# ================================
# 1. Stato condiviso
# ================================
class ChatState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    lore: str | None
    domain: str | None
    problem: str | None
    validation: str | None
    error_message: str | None


# ================================
# 2. Tools LangChain
# ================================
@tool
def generate_pddl_from_lore(lore: str) -> dict:
    """
    Generate domain and problem PDDL files from a given lore in JSON format.
    """
    prompt, _ = build_prompt_from_lore(json.loads(lore))
    result = ask_ollama(prompt)
    domain = extract_between(result, "=== DOMAIN START ===", "=== DOMAIN END ===")
    problem = extract_between(result, "=== PROBLEM START ===", "=== PROBLEM END ===")
    return {"domain": domain, "problem": problem, "lore": lore}


@tool
def validate(domain: str, problem: str, lore: str) -> dict:
    """
    Validate the given domain and problem PDDL files using the provided lore.
    """
    validation = validate_pddl(domain, problem, json.loads(lore))
    return {
        "validation": str(validation),
        "error_message": None if validation.get("valid_syntax") else "Invalid syntax"
    }


@tool
def reflect(domain: str, problem: str, error_message: str, lore: str) -> dict:
    """
    Refine the PDDL files based on the validation error and the given lore.
    """
    os.makedirs("TEMP", exist_ok=True)
    save_text_file("TEMP/domain.pddl", domain)
    save_text_file("TEMP/problem.pddl", problem)

    refined = refine_pddl(
        domain_path="TEMP/domain.pddl",
        problem_path="TEMP/problem.pddl",
        error_message=error_message,
        lore=json.loads(lore)
    )

    domain = extract_between(refined, "=== DOMAIN START ===", "=== DOMAIN END ===")
    problem = extract_between(refined, "=== PROBLEM START ===", "=== PROBLEM END ===")
    return {"domain": domain, "problem": problem}


# ================================
# 3. Setup LLM con Tools
# ================================
tools = [generate_pddl_from_lore, validate, reflect]
llm = ChatOllama(model="mistral")
llm_with_tools = llm.bind_tools(tools)


# ================================
# 4. Costruzione del grafo
# ================================
def chat_node(state: ChatState) -> dict:
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

builder = StateGraph(ChatState)
builder.add_node("chat", chat_node)
builder.add_node("tools", ToolNode(tools=tools))
builder.add_conditional_edges("chat", path=tools_condition)
builder.add_edge("tools", "chat")
builder.add_edge(START, "chat")

graph = builder.compile()


# ================================
# 5. Gestione memoria persistente
# ================================
def get_memory_for_thread(thread_id: str) -> MemorySaver:
    memory_dir = "memory"
    os.makedirs(memory_dir, exist_ok=True)
    return MemorySaver.from_path(os.path.join(memory_dir, f"{thread_id}.json"))  # type: ignore[attr-defined]


# ================================
# 6. Loop REPL o API
# ================================
def process_input(user_input: str, thread_id: str):
    # Comando per reset della memoria
    if user_input.strip().lower() == "/reset":
        path = os.path.join("memory", f"{thread_id}.json")
        if os.path.exists(path):
            os.remove(path)
            print("ğŸ”„ Memoria del thread resettata.")
        else:
            print("â„¹ï¸ Nessuna memoria da resettare.")
        return

    state = {"messages": [{"role": "user", "content": user_input}]}
    config = {"configurable": {"thread_id": thread_id}}

    memory = get_memory_for_thread(thread_id)
    graph_with_memory = graph.with_config(checkpointer=memory)

    for update in graph_with_memory.stream(state, config, stream_mode="values"):
        response_msg = update["messages"][-1]
        print(f"ğŸ¤–: {response_msg.content}")


# ================================
# 7. Esecuzione CLI
# ================================
if __name__ == "__main__":
    print("== QuestMaster ChatBot ğŸ§  ==")
    thread = input("ğŸ§µ Thread ID: ")
    while True:
        user_msg = input("ğŸ‘¤ Tu: ")
        if user_msg.lower() in {"q", "quit", "exit"}:
            break
        process_input(user_msg, thread)
